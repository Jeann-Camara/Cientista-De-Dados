{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando um Dataframe vazio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'data.frame'"
      ],
      "text/latex": [
       "'data.frame'"
      ],
      "text/markdown": [
       "'data.frame'"
      ],
      "text/plain": [
       "[1] \"data.frame\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/latex": [],
      "text/markdown": [],
      "text/plain": [
       "<0 x 0 matrix>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df <- data.frame()\n",
    "class(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando vetores vazios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>c.nomes..idades..itens..codigos.</th></tr></thead>\n",
       "<tbody>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       " c.nomes..idades..itens..codigos.\\\\\n",
       "\\hline\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "c.nomes..idades..itens..codigos. | \n",
       "||\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     c.nomes..idades..itens..codigos."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nomes <- character()\n",
    "idades <- numeric()\n",
    "itens <- numeric()\n",
    "codigos <- integer()\n",
    "\n",
    "df <- data.frame(c(nomes, idades, itens, codigos)) \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando vetores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pais = c(\"Portugal\", \"Inglaterra\", \"Irlanda\", \"Egito\", \"Brasil\")\n",
    "nome = c(\"Bruno\", \"Tiago\", \"Amanda\", \"Bianca\", \"Marta\")\n",
    "altura = c(1.88, 1.76, 1.53, 1.69, 1.68)\n",
    "codigo = c(5001, 2183, 4702, 7965, 8890)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando um Dataframe de diversos vetores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>pais</th><th scope=col>nome</th><th scope=col>altura</th><th scope=col>codigo</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Portugal  </td><td>Bruno     </td><td>1.88      </td><td>5001      </td></tr>\n",
       "\t<tr><td>Inglaterra</td><td>Tiago     </td><td>1.76      </td><td>2183      </td></tr>\n",
       "\t<tr><td>Irlanda   </td><td>Amanda    </td><td>1.53      </td><td>4702      </td></tr>\n",
       "\t<tr><td>Egito     </td><td>Bianca    </td><td>1.69      </td><td>7965      </td></tr>\n",
       "\t<tr><td>Brasil    </td><td>Marta     </td><td>1.68      </td><td>8890      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " pais & nome & altura & codigo\\\\\n",
       "\\hline\n",
       "\t Portugal   & Bruno      & 1.88       & 5001      \\\\\n",
       "\t Inglaterra & Tiago      & 1.76       & 2183      \\\\\n",
       "\t Irlanda    & Amanda     & 1.53       & 4702      \\\\\n",
       "\t Egito      & Bianca     & 1.69       & 7965      \\\\\n",
       "\t Brasil     & Marta      & 1.68       & 8890      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "pais | nome | altura | codigo | \n",
       "|---|---|---|---|---|\n",
       "| Portugal   | Bruno      | 1.88       | 5001       | \n",
       "| Inglaterra | Tiago      | 1.76       | 2183       | \n",
       "| Irlanda    | Amanda     | 1.53       | 4702       | \n",
       "| Egito      | Bianca     | 1.69       | 7965       | \n",
       "| Brasil     | Marta      | 1.68       | 8890       | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  pais       nome   altura codigo\n",
       "1 Portugal   Bruno  1.88   5001  \n",
       "2 Inglaterra Tiago  1.76   2183  \n",
       "3 Irlanda    Amanda 1.53   4702  \n",
       "4 Egito      Bianca 1.69   7965  \n",
       "5 Brasil     Marta  1.68   8890  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pesquisa = data.frame(pais, nome, altura, codigo)\n",
    "pesquisa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adicionando um novo vetor à um Dataframe existente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>pais</th><th scope=col>nome</th><th scope=col>altura</th><th scope=col>codigo</th><th scope=col>olhos</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Portugal  </td><td>Bruno     </td><td>1.88      </td><td>5001      </td><td>Verde     </td></tr>\n",
       "\t<tr><td>Inglaterra</td><td>Tiago     </td><td>1.76      </td><td>2183      </td><td>azul      </td></tr>\n",
       "\t<tr><td>Irlanda   </td><td>Amanda    </td><td>1.53      </td><td>4702      </td><td>azul      </td></tr>\n",
       "\t<tr><td>Egito     </td><td>Bianca    </td><td>1.69      </td><td>7965      </td><td>castanho  </td></tr>\n",
       "\t<tr><td>Brasil    </td><td>Marta     </td><td>1.68      </td><td>8890      </td><td>castanho  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " pais & nome & altura & codigo & olhos\\\\\n",
       "\\hline\n",
       "\t Portugal   & Bruno      & 1.88       & 5001       & Verde     \\\\\n",
       "\t Inglaterra & Tiago      & 1.76       & 2183       & azul      \\\\\n",
       "\t Irlanda    & Amanda     & 1.53       & 4702       & azul      \\\\\n",
       "\t Egito      & Bianca     & 1.69       & 7965       & castanho  \\\\\n",
       "\t Brasil     & Marta      & 1.68       & 8890       & castanho  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "pais | nome | altura | codigo | olhos | \n",
       "|---|---|---|---|---|\n",
       "| Portugal   | Bruno      | 1.88       | 5001       | Verde      | \n",
       "| Inglaterra | Tiago      | 1.76       | 2183       | azul       | \n",
       "| Irlanda    | Amanda     | 1.53       | 4702       | azul       | \n",
       "| Egito      | Bianca     | 1.69       | 7965       | castanho   | \n",
       "| Brasil     | Marta      | 1.68       | 8890       | castanho   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  pais       nome   altura codigo olhos   \n",
       "1 Portugal   Bruno  1.88   5001   Verde   \n",
       "2 Inglaterra Tiago  1.76   2183   azul    \n",
       "3 Irlanda    Amanda 1.53   4702   azul    \n",
       "4 Egito      Bianca 1.69   7965   castanho\n",
       "5 Brasil     Marta  1.68   8890   castanho"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "olhos = c(\"Verde\", \"azul\", \"azul\", \"castanho\", \"castanho\")\n",
    "pesq = cbind(pesquisa, olhos)\n",
    "pesq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informações sobre o Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t5 obs. of  5 variables:\n",
      " $ pais  : Factor w/ 5 levels \"Brasil\",\"Egito\",..: 5 3 4 2 1\n",
      " $ nome  : Factor w/ 5 levels \"Amanda\",\"Bianca\",..: 3 5 1 2 4\n",
      " $ altura: num  1.88 1.76 1.53 1.69 1.68\n",
      " $ codigo: num  5001 2183 4702 7965 8890\n",
      " $ olhos : Factor w/ 3 levels \"azul\",\"castanho\",..: 3 1 1 2 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>5</li>\n",
       "\t<li>5</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 5\n",
       "\\item 5\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 5\n",
       "2. 5\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 5 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "5"
      ],
      "text/latex": [
       "5"
      ],
      "text/markdown": [
       "5"
      ],
      "text/plain": [
       "[1] 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "str(pesq)\n",
    "dim(pesq)\n",
    "length(pesq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtendo um vetor de um Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>Portugal</li>\n",
       "\t<li>Inglaterra</li>\n",
       "\t<li>Irlanda</li>\n",
       "\t<li>Egito</li>\n",
       "\t<li>Brasil</li>\n",
       "</ol>\n",
       "\n",
       "<details>\n",
       "\t<summary style=display:list-item;cursor:pointer>\n",
       "\t\t<strong>Levels</strong>:\n",
       "\t</summary>\n",
       "\t<ol class=list-inline>\n",
       "\t\t<li>'Brasil'</li>\n",
       "\t\t<li>'Egito'</li>\n",
       "\t\t<li>'Inglaterra'</li>\n",
       "\t\t<li>'Irlanda'</li>\n",
       "\t\t<li>'Portugal'</li>\n",
       "\t</ol>\n",
       "</details>"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item Portugal\n",
       "\\item Inglaterra\n",
       "\\item Irlanda\n",
       "\\item Egito\n",
       "\\item Brasil\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\emph{Levels}: \\begin{enumerate*}\n",
       "\\item 'Brasil'\n",
       "\\item 'Egito'\n",
       "\\item 'Inglaterra'\n",
       "\\item 'Irlanda'\n",
       "\\item 'Portugal'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. Portugal\n",
       "2. Inglaterra\n",
       "3. Irlanda\n",
       "4. Egito\n",
       "5. Brasil\n",
       "\n",
       "\n",
       "\n",
       "**Levels**: 1. 'Brasil'\n",
       "2. 'Egito'\n",
       "3. 'Inglaterra'\n",
       "4. 'Irlanda'\n",
       "5. 'Portugal'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] Portugal   Inglaterra Irlanda    Egito      Brasil    \n",
       "Levels: Brasil Egito Inglaterra Irlanda Portugal"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>Bruno</li>\n",
       "\t<li>Tiago</li>\n",
       "\t<li>Amanda</li>\n",
       "\t<li>Bianca</li>\n",
       "\t<li>Marta</li>\n",
       "</ol>\n",
       "\n",
       "<details>\n",
       "\t<summary style=display:list-item;cursor:pointer>\n",
       "\t\t<strong>Levels</strong>:\n",
       "\t</summary>\n",
       "\t<ol class=list-inline>\n",
       "\t\t<li>'Amanda'</li>\n",
       "\t\t<li>'Bianca'</li>\n",
       "\t\t<li>'Bruno'</li>\n",
       "\t\t<li>'Marta'</li>\n",
       "\t\t<li>'Tiago'</li>\n",
       "\t</ol>\n",
       "</details>"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item Bruno\n",
       "\\item Tiago\n",
       "\\item Amanda\n",
       "\\item Bianca\n",
       "\\item Marta\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\emph{Levels}: \\begin{enumerate*}\n",
       "\\item 'Amanda'\n",
       "\\item 'Bianca'\n",
       "\\item 'Bruno'\n",
       "\\item 'Marta'\n",
       "\\item 'Tiago'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. Bruno\n",
       "2. Tiago\n",
       "3. Amanda\n",
       "4. Bianca\n",
       "5. Marta\n",
       "\n",
       "\n",
       "\n",
       "**Levels**: 1. 'Amanda'\n",
       "2. 'Bianca'\n",
       "3. 'Bruno'\n",
       "4. 'Marta'\n",
       "5. 'Tiago'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] Bruno  Tiago  Amanda Bianca Marta \n",
       "Levels: Amanda Bianca Bruno Marta Tiago"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pesq$pais\n",
    "pesq$nome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraindo um único valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pesq[1,1]\n",
    "pesq[3,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Número de linhas e colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "5"
      ],
      "text/latex": [
       "5"
      ],
      "text/markdown": [
       "5"
      ],
      "text/plain": [
       "[1] 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "5"
      ],
      "text/latex": [
       "5"
      ],
      "text/markdown": [
       "5"
      ],
      "text/plain": [
       "[1] 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nrow(pesq)\n",
    "ncol(pesq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primeiros elementos do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>pais</th><th scope=col>nome</th><th scope=col>altura</th><th scope=col>codigo</th><th scope=col>olhos</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Portugal  </td><td>Bruno     </td><td>1.88      </td><td>5001      </td><td>Verde     </td></tr>\n",
       "\t<tr><td>Inglaterra</td><td>Tiago     </td><td>1.76      </td><td>2183      </td><td>azul      </td></tr>\n",
       "\t<tr><td>Irlanda   </td><td>Amanda    </td><td>1.53      </td><td>4702      </td><td>azul      </td></tr>\n",
       "\t<tr><td>Egito     </td><td>Bianca    </td><td>1.69      </td><td>7965      </td><td>castanho  </td></tr>\n",
       "\t<tr><td>Brasil    </td><td>Marta     </td><td>1.68      </td><td>8890      </td><td>castanho  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " pais & nome & altura & codigo & olhos\\\\\n",
       "\\hline\n",
       "\t Portugal   & Bruno      & 1.88       & 5001       & Verde     \\\\\n",
       "\t Inglaterra & Tiago      & 1.76       & 2183       & azul      \\\\\n",
       "\t Irlanda    & Amanda     & 1.53       & 4702       & azul      \\\\\n",
       "\t Egito      & Bianca     & 1.69       & 7965       & castanho  \\\\\n",
       "\t Brasil     & Marta      & 1.68       & 8890       & castanho  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "pais | nome | altura | codigo | olhos | \n",
       "|---|---|---|---|---|\n",
       "| Portugal   | Bruno      | 1.88       | 5001       | Verde      | \n",
       "| Inglaterra | Tiago      | 1.76       | 2183       | azul       | \n",
       "| Irlanda    | Amanda     | 1.53       | 4702       | azul       | \n",
       "| Egito      | Bianca     | 1.69       | 7965       | castanho   | \n",
       "| Brasil     | Marta      | 1.68       | 8890       | castanho   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  pais       nome   altura codigo olhos   \n",
       "1 Portugal   Bruno  1.88   5001   Verde   \n",
       "2 Inglaterra Tiago  1.76   2183   azul    \n",
       "3 Irlanda    Amanda 1.53   4702   azul    \n",
       "4 Egito      Bianca 1.69   7965   castanho\n",
       "5 Brasil     Marta  1.68   8890   castanho"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>mpg</th><th scope=col>cyl</th><th scope=col>disp</th><th scope=col>hp</th><th scope=col>drat</th><th scope=col>wt</th><th scope=col>qsec</th><th scope=col>vs</th><th scope=col>am</th><th scope=col>gear</th><th scope=col>carb</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Mazda RX4</th><td>21.0 </td><td>6    </td><td>160  </td><td>110  </td><td>3.90 </td><td>2.620</td><td>16.46</td><td>0    </td><td>1    </td><td>4    </td><td>4    </td></tr>\n",
       "\t<tr><th scope=row>Mazda RX4 Wag</th><td>21.0 </td><td>6    </td><td>160  </td><td>110  </td><td>3.90 </td><td>2.875</td><td>17.02</td><td>0    </td><td>1    </td><td>4    </td><td>4    </td></tr>\n",
       "\t<tr><th scope=row>Datsun 710</th><td>22.8 </td><td>4    </td><td>108  </td><td> 93  </td><td>3.85 </td><td>2.320</td><td>18.61</td><td>1    </td><td>1    </td><td>4    </td><td>1    </td></tr>\n",
       "\t<tr><th scope=row>Hornet 4 Drive</th><td>21.4 </td><td>6    </td><td>258  </td><td>110  </td><td>3.08 </td><td>3.215</td><td>19.44</td><td>1    </td><td>0    </td><td>3    </td><td>1    </td></tr>\n",
       "\t<tr><th scope=row>Hornet Sportabout</th><td>18.7 </td><td>8    </td><td>360  </td><td>175  </td><td>3.15 </td><td>3.440</td><td>17.02</td><td>0    </td><td>0    </td><td>3    </td><td>2    </td></tr>\n",
       "\t<tr><th scope=row>Valiant</th><td>18.1 </td><td>6    </td><td>225  </td><td>105  </td><td>2.76 </td><td>3.460</td><td>20.22</td><td>1    </td><td>0    </td><td>3    </td><td>1    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllll}\n",
       "  & mpg & cyl & disp & hp & drat & wt & qsec & vs & am & gear & carb\\\\\n",
       "\\hline\n",
       "\tMazda RX4 & 21.0  & 6     & 160   & 110   & 3.90  & 2.620 & 16.46 & 0     & 1     & 4     & 4    \\\\\n",
       "\tMazda RX4 Wag & 21.0  & 6     & 160   & 110   & 3.90  & 2.875 & 17.02 & 0     & 1     & 4     & 4    \\\\\n",
       "\tDatsun 710 & 22.8  & 4     & 108   &  93   & 3.85  & 2.320 & 18.61 & 1     & 1     & 4     & 1    \\\\\n",
       "\tHornet 4 Drive & 21.4  & 6     & 258   & 110   & 3.08  & 3.215 & 19.44 & 1     & 0     & 3     & 1    \\\\\n",
       "\tHornet Sportabout & 18.7  & 8     & 360   & 175   & 3.15  & 3.440 & 17.02 & 0     & 0     & 3     & 2    \\\\\n",
       "\tValiant & 18.1  & 6     & 225   & 105   & 2.76  & 3.460 & 20.22 & 1     & 0     & 3     & 1    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | mpg | cyl | disp | hp | drat | wt | qsec | vs | am | gear | carb | \n",
       "|---|---|---|---|---|---|\n",
       "| Mazda RX4 | 21.0  | 6     | 160   | 110   | 3.90  | 2.620 | 16.46 | 0     | 1     | 4     | 4     | \n",
       "| Mazda RX4 Wag | 21.0  | 6     | 160   | 110   | 3.90  | 2.875 | 17.02 | 0     | 1     | 4     | 4     | \n",
       "| Datsun 710 | 22.8  | 4     | 108   |  93   | 3.85  | 2.320 | 18.61 | 1     | 1     | 4     | 1     | \n",
       "| Hornet 4 Drive | 21.4  | 6     | 258   | 110   | 3.08  | 3.215 | 19.44 | 1     | 0     | 3     | 1     | \n",
       "| Hornet Sportabout | 18.7  | 8     | 360   | 175   | 3.15  | 3.440 | 17.02 | 0     | 0     | 3     | 2     | \n",
       "| Valiant | 18.1  | 6     | 225   | 105   | 2.76  | 3.460 | 20.22 | 1     | 0     | 3     | 1     | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "                  mpg  cyl disp hp  drat wt    qsec  vs am gear carb\n",
       "Mazda RX4         21.0 6   160  110 3.90 2.620 16.46 0  1  4    4   \n",
       "Mazda RX4 Wag     21.0 6   160  110 3.90 2.875 17.02 0  1  4    4   \n",
       "Datsun 710        22.8 4   108   93 3.85 2.320 18.61 1  1  4    1   \n",
       "Hornet 4 Drive    21.4 6   258  110 3.08 3.215 19.44 1  0  3    1   \n",
       "Hornet Sportabout 18.7 8   360  175 3.15 3.440 17.02 0  0  3    2   \n",
       "Valiant           18.1 6   225  105 2.76 3.460 20.22 1  0  3    1   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(pesq)\n",
    "head(mtcars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Últimos elementos do Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>pais</th><th scope=col>nome</th><th scope=col>altura</th><th scope=col>codigo</th><th scope=col>olhos</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Portugal  </td><td>Bruno     </td><td>1.88      </td><td>5001      </td><td>Verde     </td></tr>\n",
       "\t<tr><td>Inglaterra</td><td>Tiago     </td><td>1.76      </td><td>2183      </td><td>azul      </td></tr>\n",
       "\t<tr><td>Irlanda   </td><td>Amanda    </td><td>1.53      </td><td>4702      </td><td>azul      </td></tr>\n",
       "\t<tr><td>Egito     </td><td>Bianca    </td><td>1.69      </td><td>7965      </td><td>castanho  </td></tr>\n",
       "\t<tr><td>Brasil    </td><td>Marta     </td><td>1.68      </td><td>8890      </td><td>castanho  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " pais & nome & altura & codigo & olhos\\\\\n",
       "\\hline\n",
       "\t Portugal   & Bruno      & 1.88       & 5001       & Verde     \\\\\n",
       "\t Inglaterra & Tiago      & 1.76       & 2183       & azul      \\\\\n",
       "\t Irlanda    & Amanda     & 1.53       & 4702       & azul      \\\\\n",
       "\t Egito      & Bianca     & 1.69       & 7965       & castanho  \\\\\n",
       "\t Brasil     & Marta      & 1.68       & 8890       & castanho  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "pais | nome | altura | codigo | olhos | \n",
       "|---|---|---|---|---|\n",
       "| Portugal   | Bruno      | 1.88       | 5001       | Verde      | \n",
       "| Inglaterra | Tiago      | 1.76       | 2183       | azul       | \n",
       "| Irlanda    | Amanda     | 1.53       | 4702       | azul       | \n",
       "| Egito      | Bianca     | 1.69       | 7965       | castanho   | \n",
       "| Brasil     | Marta      | 1.68       | 8890       | castanho   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  pais       nome   altura codigo olhos   \n",
       "1 Portugal   Bruno  1.88   5001   Verde   \n",
       "2 Inglaterra Tiago  1.76   2183   azul    \n",
       "3 Irlanda    Amanda 1.53   4702   azul    \n",
       "4 Egito      Bianca 1.69   7965   castanho\n",
       "5 Brasil     Marta  1.68   8890   castanho"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>mpg</th><th scope=col>cyl</th><th scope=col>disp</th><th scope=col>hp</th><th scope=col>drat</th><th scope=col>wt</th><th scope=col>qsec</th><th scope=col>vs</th><th scope=col>am</th><th scope=col>gear</th><th scope=col>carb</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Porsche 914-2</th><td>26.0 </td><td>4    </td><td>120.3</td><td> 91  </td><td>4.43 </td><td>2.140</td><td>16.7 </td><td>0    </td><td>1    </td><td>5    </td><td>2    </td></tr>\n",
       "\t<tr><th scope=row>Lotus Europa</th><td>30.4 </td><td>4    </td><td> 95.1</td><td>113  </td><td>3.77 </td><td>1.513</td><td>16.9 </td><td>1    </td><td>1    </td><td>5    </td><td>2    </td></tr>\n",
       "\t<tr><th scope=row>Ford Pantera L</th><td>15.8 </td><td>8    </td><td>351.0</td><td>264  </td><td>4.22 </td><td>3.170</td><td>14.5 </td><td>0    </td><td>1    </td><td>5    </td><td>4    </td></tr>\n",
       "\t<tr><th scope=row>Ferrari Dino</th><td>19.7 </td><td>6    </td><td>145.0</td><td>175  </td><td>3.62 </td><td>2.770</td><td>15.5 </td><td>0    </td><td>1    </td><td>5    </td><td>6    </td></tr>\n",
       "\t<tr><th scope=row>Maserati Bora</th><td>15.0 </td><td>8    </td><td>301.0</td><td>335  </td><td>3.54 </td><td>3.570</td><td>14.6 </td><td>0    </td><td>1    </td><td>5    </td><td>8    </td></tr>\n",
       "\t<tr><th scope=row>Volvo 142E</th><td>21.4 </td><td>4    </td><td>121.0</td><td>109  </td><td>4.11 </td><td>2.780</td><td>18.6 </td><td>1    </td><td>1    </td><td>4    </td><td>2    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllll}\n",
       "  & mpg & cyl & disp & hp & drat & wt & qsec & vs & am & gear & carb\\\\\n",
       "\\hline\n",
       "\tPorsche 914-2 & 26.0  & 4     & 120.3 &  91   & 4.43  & 2.140 & 16.7  & 0     & 1     & 5     & 2    \\\\\n",
       "\tLotus Europa & 30.4  & 4     &  95.1 & 113   & 3.77  & 1.513 & 16.9  & 1     & 1     & 5     & 2    \\\\\n",
       "\tFord Pantera L & 15.8  & 8     & 351.0 & 264   & 4.22  & 3.170 & 14.5  & 0     & 1     & 5     & 4    \\\\\n",
       "\tFerrari Dino & 19.7  & 6     & 145.0 & 175   & 3.62  & 2.770 & 15.5  & 0     & 1     & 5     & 6    \\\\\n",
       "\tMaserati Bora & 15.0  & 8     & 301.0 & 335   & 3.54  & 3.570 & 14.6  & 0     & 1     & 5     & 8    \\\\\n",
       "\tVolvo 142E & 21.4  & 4     & 121.0 & 109   & 4.11  & 2.780 & 18.6  & 1     & 1     & 4     & 2    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | mpg | cyl | disp | hp | drat | wt | qsec | vs | am | gear | carb | \n",
       "|---|---|---|---|---|---|\n",
       "| Porsche 914-2 | 26.0  | 4     | 120.3 |  91   | 4.43  | 2.140 | 16.7  | 0     | 1     | 5     | 2     | \n",
       "| Lotus Europa | 30.4  | 4     |  95.1 | 113   | 3.77  | 1.513 | 16.9  | 1     | 1     | 5     | 2     | \n",
       "| Ford Pantera L | 15.8  | 8     | 351.0 | 264   | 4.22  | 3.170 | 14.5  | 0     | 1     | 5     | 4     | \n",
       "| Ferrari Dino | 19.7  | 6     | 145.0 | 175   | 3.62  | 2.770 | 15.5  | 0     | 1     | 5     | 6     | \n",
       "| Maserati Bora | 15.0  | 8     | 301.0 | 335   | 3.54  | 3.570 | 14.6  | 0     | 1     | 5     | 8     | \n",
       "| Volvo 142E | 21.4  | 4     | 121.0 | 109   | 4.11  | 2.780 | 18.6  | 1     | 1     | 4     | 2     | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "               mpg  cyl disp  hp  drat wt    qsec vs am gear carb\n",
       "Porsche 914-2  26.0 4   120.3  91 4.43 2.140 16.7 0  1  5    2   \n",
       "Lotus Europa   30.4 4    95.1 113 3.77 1.513 16.9 1  1  5    2   \n",
       "Ford Pantera L 15.8 8   351.0 264 4.22 3.170 14.5 0  1  5    4   \n",
       "Ferrari Dino   19.7 6   145.0 175 3.62 2.770 15.5 0  1  5    6   \n",
       "Maserati Bora  15.0 8   301.0 335 3.54 3.570 14.6 0  1  5    8   \n",
       "Volvo 142E     21.4 4   121.0 109 4.11 2.780 18.6 1  1  4    2   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tail(pesq)\n",
    "tail(mtcars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtro para um subset de dados que atendem a um critério"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>pais</th><th scope=col>nome</th><th scope=col>altura</th><th scope=col>codigo</th><th scope=col>olhos</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>3</th><td>Irlanda</td><td>Amanda </td><td>1.53   </td><td>4702   </td><td>azul   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "  & pais & nome & altura & codigo & olhos\\\\\n",
       "\\hline\n",
       "\t3 & Irlanda & Amanda  & 1.53    & 4702    & azul   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | pais | nome | altura | codigo | olhos | \n",
       "|---|\n",
       "| 3 | Irlanda | Amanda  | 1.53    | 4702    | azul    | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  pais    nome   altura codigo olhos\n",
       "3 Irlanda Amanda 1.53   4702   azul "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>codigo</th><th scope=col>olhos</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>3</th><td>4702</td><td>azul</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & codigo & olhos\\\\\n",
       "\\hline\n",
       "\t3 & 4702 & azul\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | codigo | olhos | \n",
       "|---|\n",
       "| 3 | 4702 | azul | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  codigo olhos\n",
       "3 4702   azul "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>pais</th><th scope=col>nome</th><th scope=col>altura</th><th scope=col>codigo</th><th scope=col>olhos</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Portugal  </td><td>Bruno     </td><td>1.88      </td><td>5001      </td><td>Verde     </td></tr>\n",
       "\t<tr><td>Inglaterra</td><td>Tiago     </td><td>1.76      </td><td>2183      </td><td>azul      </td></tr>\n",
       "\t<tr><td>Irlanda   </td><td>Amanda    </td><td>1.53      </td><td>4702      </td><td>azul      </td></tr>\n",
       "\t<tr><td>Egito     </td><td>Bianca    </td><td>1.69      </td><td>7965      </td><td>castanho  </td></tr>\n",
       "\t<tr><td>Brasil    </td><td>Marta     </td><td>1.68      </td><td>8890      </td><td>castanho  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " pais & nome & altura & codigo & olhos\\\\\n",
       "\\hline\n",
       "\t Portugal   & Bruno      & 1.88       & 5001       & Verde     \\\\\n",
       "\t Inglaterra & Tiago      & 1.76       & 2183       & azul      \\\\\n",
       "\t Irlanda    & Amanda     & 1.53       & 4702       & azul      \\\\\n",
       "\t Egito      & Bianca     & 1.69       & 7965       & castanho  \\\\\n",
       "\t Brasil     & Marta      & 1.68       & 8890       & castanho  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "pais | nome | altura | codigo | olhos | \n",
       "|---|---|---|---|---|\n",
       "| Portugal   | Bruno      | 1.88       | 5001       | Verde      | \n",
       "| Inglaterra | Tiago      | 1.76       | 2183       | azul       | \n",
       "| Irlanda    | Amanda     | 1.53       | 4702       | azul       | \n",
       "| Egito      | Bianca     | 1.69       | 7965       | castanho   | \n",
       "| Brasil     | Marta      | 1.68       | 8890       | castanho   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  pais       nome   altura codigo olhos   \n",
       "1 Portugal   Bruno  1.88   5001   Verde   \n",
       "2 Inglaterra Tiago  1.76   2183   azul    \n",
       "3 Irlanda    Amanda 1.53   4702   azul    \n",
       "4 Egito      Bianca 1.69   7965   castanho\n",
       "5 Brasil     Marta  1.68   8890   castanho"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pesq[altura < 1.60,]\n",
    "pesq[altura < 1.60, c(\"codigo\",\"olhos\")]\n",
    "pesq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes nomeados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>País</th><th scope=col>Nome</th><th scope=col>Altura</th><th scope=col>Código</th><th scope=col>Olhos</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Portugal  </td><td>Bruno     </td><td>1.88      </td><td>5001      </td><td>Verde     </td></tr>\n",
       "\t<tr><td>Inglaterra</td><td>Tiago     </td><td>1.76      </td><td>2183      </td><td>azul      </td></tr>\n",
       "\t<tr><td>Irlanda   </td><td>Amanda    </td><td>1.53      </td><td>4702      </td><td>azul      </td></tr>\n",
       "\t<tr><td>Egito     </td><td>Bianca    </td><td>1.69      </td><td>7965      </td><td>castanho  </td></tr>\n",
       "\t<tr><td>Brasil    </td><td>Marta     </td><td>1.68      </td><td>8890      </td><td>castanho  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " País & Nome & Altura & Código & Olhos\\\\\n",
       "\\hline\n",
       "\t Portugal   & Bruno      & 1.88       & 5001       & Verde     \\\\\n",
       "\t Inglaterra & Tiago      & 1.76       & 2183       & azul      \\\\\n",
       "\t Irlanda    & Amanda     & 1.53       & 4702       & azul      \\\\\n",
       "\t Egito      & Bianca     & 1.69       & 7965       & castanho  \\\\\n",
       "\t Brasil     & Marta      & 1.68       & 8890       & castanho  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "País | Nome | Altura | Código | Olhos | \n",
       "|---|---|---|---|---|\n",
       "| Portugal   | Bruno      | 1.88       | 5001       | Verde      | \n",
       "| Inglaterra | Tiago      | 1.76       | 2183       | azul       | \n",
       "| Irlanda    | Amanda     | 1.53       | 4702       | azul       | \n",
       "| Egito      | Bianca     | 1.69       | 7965       | castanho   | \n",
       "| Brasil     | Marta      | 1.68       | 8890       | castanho   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  País       Nome   Altura Código Olhos   \n",
       "1 Portugal   Bruno  1.88   5001   Verde   \n",
       "2 Inglaterra Tiago  1.76   2183   azul    \n",
       "3 Irlanda    Amanda 1.53   4702   azul    \n",
       "4 Egito      Bianca 1.69   7965   castanho\n",
       "5 Brasil     Marta  1.68   8890   castanho"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names(pesq) <- c(\"País\", \"Nome\", \"Altura\", \"Código\", \"Olhos\")\n",
    "pesq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>var 1</th><th scope=col>var 2</th><th scope=col>var 3</th><th scope=col>var 4</th><th scope=col>var 5</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>obs 1</th><td>Portugal  </td><td>Bruno     </td><td>1.88      </td><td>5001      </td><td>Verde     </td></tr>\n",
       "\t<tr><th scope=row>obs 2</th><td>Inglaterra</td><td>Tiago     </td><td>1.76      </td><td>2183      </td><td>azul      </td></tr>\n",
       "\t<tr><th scope=row>obs 3</th><td>Irlanda   </td><td>Amanda    </td><td>1.53      </td><td>4702      </td><td>azul      </td></tr>\n",
       "\t<tr><th scope=row>obs 4</th><td>Egito     </td><td>Bianca    </td><td>1.69      </td><td>7965      </td><td>castanho  </td></tr>\n",
       "\t<tr><th scope=row>obs 5</th><td>Brasil    </td><td>Marta     </td><td>1.68      </td><td>8890      </td><td>castanho  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "  & var 1 & var 2 & var 3 & var 4 & var 5\\\\\n",
       "\\hline\n",
       "\tobs 1 & Portugal   & Bruno      & 1.88       & 5001       & Verde     \\\\\n",
       "\tobs 2 & Inglaterra & Tiago      & 1.76       & 2183       & azul      \\\\\n",
       "\tobs 3 & Irlanda    & Amanda     & 1.53       & 4702       & azul      \\\\\n",
       "\tobs 4 & Egito      & Bianca     & 1.69       & 7965       & castanho  \\\\\n",
       "\tobs 5 & Brasil     & Marta      & 1.68       & 8890       & castanho  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | var 1 | var 2 | var 3 | var 4 | var 5 | \n",
       "|---|---|---|---|---|\n",
       "| obs 1 | Portugal   | Bruno      | 1.88       | 5001       | Verde      | \n",
       "| obs 2 | Inglaterra | Tiago      | 1.76       | 2183       | azul       | \n",
       "| obs 3 | Irlanda    | Amanda     | 1.53       | 4702       | azul       | \n",
       "| obs 4 | Egito      | Bianca     | 1.69       | 7965       | castanho   | \n",
       "| obs 5 | Brasil     | Marta      | 1.68       | 8890       | castanho   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "      var 1      var 2  var 3 var 4 var 5   \n",
       "obs 1 Portugal   Bruno  1.88  5001  Verde   \n",
       "obs 2 Inglaterra Tiago  1.76  2183  azul    \n",
       "obs 3 Irlanda    Amanda 1.53  4702  azul    \n",
       "obs 4 Egito      Bianca 1.69  7965  castanho\n",
       "obs 5 Brasil     Marta  1.68  8890  castanho"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colnames(pesq) <- c(\"var 1\", \"var 2\", \"var 3\", \"var 4\", \"var 5\")\n",
    "rownames(pesq) <- c(\"obs 1\", \"obs 2\", \"obs 3\", \"obs 4\", \"obs 5\")\n",
    "pesq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando um arquivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacientes <- data.frame(read.csv(file = \"pacientes.csv\", header = TRUE, sep = \",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>ID</th><th scope=col>Nome</th><th scope=col>Idade</th><th scope=col>Admdate</th><th scope=col>Diabete</th><th scope=col>Status</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1         </td><td>Paciente 1</td><td>43        </td><td>15/10/2015</td><td>Tipo 1    </td><td>Ruim      </td></tr>\n",
       "\t<tr><td>2         </td><td>Paciente 2</td><td>23        </td><td>16/10/2015</td><td>Tipo 2    </td><td>Bom       </td></tr>\n",
       "\t<tr><td>3         </td><td>Paciente 3</td><td>56        </td><td>23/10/2015</td><td>Tipo 2    </td><td>Bom       </td></tr>\n",
       "\t<tr><td>4         </td><td>Paciente 4</td><td>34        </td><td>24/10/2015</td><td>Tipo 1    </td><td>Ruim      </td></tr>\n",
       "\t<tr><td>5         </td><td>Paciente 5</td><td>38        </td><td>31/10/2015</td><td>Tipo 1    </td><td>Medio     </td></tr>\n",
       "\t<tr><td>6         </td><td>Paciente 6</td><td>37        </td><td>28/10/2015</td><td>Tipo 1    </td><td>Bom       </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       " ID & Nome & Idade & Admdate & Diabete & Status\\\\\n",
       "\\hline\n",
       "\t 1          & Paciente 1 & 43         & 15/10/2015 & Tipo 1     & Ruim      \\\\\n",
       "\t 2          & Paciente 2 & 23         & 16/10/2015 & Tipo 2     & Bom       \\\\\n",
       "\t 3          & Paciente 3 & 56         & 23/10/2015 & Tipo 2     & Bom       \\\\\n",
       "\t 4          & Paciente 4 & 34         & 24/10/2015 & Tipo 1     & Ruim      \\\\\n",
       "\t 5          & Paciente 5 & 38         & 31/10/2015 & Tipo 1     & Medio     \\\\\n",
       "\t 6          & Paciente 6 & 37         & 28/10/2015 & Tipo 1     & Bom       \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "ID | Nome | Idade | Admdate | Diabete | Status | \n",
       "|---|---|---|---|---|---|\n",
       "| 1          | Paciente 1 | 43         | 15/10/2015 | Tipo 1     | Ruim       | \n",
       "| 2          | Paciente 2 | 23         | 16/10/2015 | Tipo 2     | Bom        | \n",
       "| 3          | Paciente 3 | 56         | 23/10/2015 | Tipo 2     | Bom        | \n",
       "| 4          | Paciente 4 | 34         | 24/10/2015 | Tipo 1     | Ruim       | \n",
       "| 5          | Paciente 5 | 38         | 31/10/2015 | Tipo 1     | Medio      | \n",
       "| 6          | Paciente 6 | 37         | 28/10/2015 | Tipo 1     | Bom        | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  ID Nome       Idade Admdate    Diabete Status\n",
       "1 1  Paciente 1 43    15/10/2015 Tipo 1  Ruim  \n",
       "2 2  Paciente 2 23    16/10/2015 Tipo 2  Bom   \n",
       "3 3  Paciente 3 56    23/10/2015 Tipo 2  Bom   \n",
       "4 4  Paciente 4 34    24/10/2015 Tipo 1  Ruim  \n",
       "5 5  Paciente 5 38    31/10/2015 Tipo 1  Medio \n",
       "6 6  Paciente 6 37    28/10/2015 Tipo 1  Bom   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "       ID              Nome       Idade             Admdate    Diabete \n",
       " Min.   :1.0   Paciente 1:1   Min.   :23.00   15/10/2015:1   Tipo 1:5  \n",
       " 1st Qu.:2.5   Paciente 2:1   1st Qu.:35.50   16/10/2015:1   Tipo 2:2  \n",
       " Median :4.0   Paciente 3:1   Median :38.00   23/10/2015:1             \n",
       " Mean   :4.0   Paciente 4:1   Mean   :38.86   24/10/2015:1             \n",
       " 3rd Qu.:5.5   Paciente 5:1   3rd Qu.:42.00   27/10/2015:1             \n",
       " Max.   :7.0   Paciente 6:1   Max.   :56.00   28/10/2015:1             \n",
       "               Paciente 7:1                   31/10/2015:1             \n",
       "   Status \n",
       " Bom  :2  \n",
       " Bom  :1  \n",
       " Medio:1  \n",
       " Ruim :3  \n",
       "          \n",
       "          \n",
       "          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(pacientes)\n",
    "summary(pacientes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizando as variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>Tipo 1</li>\n",
       "\t<li>Tipo 2</li>\n",
       "\t<li>Tipo 2</li>\n",
       "\t<li>Tipo 1</li>\n",
       "\t<li>Tipo 1</li>\n",
       "\t<li>Tipo 1</li>\n",
       "\t<li>Tipo 1</li>\n",
       "</ol>\n",
       "\n",
       "<details>\n",
       "\t<summary style=display:list-item;cursor:pointer>\n",
       "\t\t<strong>Levels</strong>:\n",
       "\t</summary>\n",
       "\t<ol class=list-inline>\n",
       "\t\t<li>'Tipo 1'</li>\n",
       "\t\t<li>'Tipo 2'</li>\n",
       "\t</ol>\n",
       "</details>"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item Tipo 1\n",
       "\\item Tipo 2\n",
       "\\item Tipo 2\n",
       "\\item Tipo 1\n",
       "\\item Tipo 1\n",
       "\\item Tipo 1\n",
       "\\item Tipo 1\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\emph{Levels}: \\begin{enumerate*}\n",
       "\\item 'Tipo 1'\n",
       "\\item 'Tipo 2'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. Tipo 1\n",
       "2. Tipo 2\n",
       "3. Tipo 2\n",
       "4. Tipo 1\n",
       "5. Tipo 1\n",
       "6. Tipo 1\n",
       "7. Tipo 1\n",
       "\n",
       "\n",
       "\n",
       "**Levels**: 1. 'Tipo 1'\n",
       "2. 'Tipo 2'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] Tipo 1 Tipo 2 Tipo 2 Tipo 1 Tipo 1 Tipo 1 Tipo 1\n",
       "Levels: Tipo 1 Tipo 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>Ruim</li>\n",
       "\t<li>Bom</li>\n",
       "\t<li>Bom</li>\n",
       "\t<li>Ruim</li>\n",
       "\t<li>Medio</li>\n",
       "\t<li>Bom </li>\n",
       "\t<li>Ruim</li>\n",
       "</ol>\n",
       "\n",
       "<details>\n",
       "\t<summary style=display:list-item;cursor:pointer>\n",
       "\t\t<strong>Levels</strong>:\n",
       "\t</summary>\n",
       "\t<ol class=list-inline>\n",
       "\t\t<li>'Bom'</li>\n",
       "\t\t<li>'Bom '</li>\n",
       "\t\t<li>'Medio'</li>\n",
       "\t\t<li>'Ruim'</li>\n",
       "\t</ol>\n",
       "</details>"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item Ruim\n",
       "\\item Bom\n",
       "\\item Bom\n",
       "\\item Ruim\n",
       "\\item Medio\n",
       "\\item Bom \n",
       "\\item Ruim\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\emph{Levels}: \\begin{enumerate*}\n",
       "\\item 'Bom'\n",
       "\\item 'Bom '\n",
       "\\item 'Medio'\n",
       "\\item 'Ruim'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. Ruim\n",
       "2. Bom\n",
       "3. Bom\n",
       "4. Ruim\n",
       "5. Medio\n",
       "6. Bom \n",
       "7. Ruim\n",
       "\n",
       "\n",
       "\n",
       "**Levels**: 1. 'Bom'\n",
       "2. 'Bom '\n",
       "3. 'Medio'\n",
       "4. 'Ruim'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] Ruim  Bom   Bom   Ruim  Medio Bom   Ruim \n",
       "Levels: Bom Bom  Medio Ruim"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pacientes$Diabete\n",
    "pacientes$Status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\ngAwQEkAG/gFKR1e5NGpllQAAAABJRU5ErkJggg==",
      "text/plain": [
       "Plot with title \"Histogram of pacientes$Idade\""
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "R display func"
    }
   ],
   "source": [
    "hist(pacientes$Idade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinando Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>var 1</th><th scope=col>var 2</th><th scope=col>var 3</th><th scope=col>var 4</th><th scope=col>var 5</th><th scope=col>ID</th><th scope=col>Nome</th><th scope=col>Idade</th><th scope=col>Admdate</th><th scope=col>Diabete</th><th scope=col>Status</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Portugal  </td><td>Bruno     </td><td>1.88      </td><td>5001      </td><td>Verde     </td><td>1         </td><td>Paciente 1</td><td>43        </td><td>15/10/2015</td><td>Tipo 1    </td><td>Ruim      </td></tr>\n",
       "\t<tr><td>Inglaterra</td><td>Tiago     </td><td>1.76      </td><td>2183      </td><td>azul      </td><td>1         </td><td>Paciente 1</td><td>43        </td><td>15/10/2015</td><td>Tipo 1    </td><td>Ruim      </td></tr>\n",
       "\t<tr><td>Irlanda   </td><td>Amanda    </td><td>1.53      </td><td>4702      </td><td>azul      </td><td>1         </td><td>Paciente 1</td><td>43        </td><td>15/10/2015</td><td>Tipo 1    </td><td>Ruim      </td></tr>\n",
       "\t<tr><td>Egito     </td><td>Bianca    </td><td>1.69      </td><td>7965      </td><td>castanho  </td><td>1         </td><td>Paciente 1</td><td>43        </td><td>15/10/2015</td><td>Tipo 1    </td><td>Ruim      </td></tr>\n",
       "\t<tr><td>Brasil    </td><td>Marta     </td><td>1.68      </td><td>8890      </td><td>castanho  </td><td>1         </td><td>Paciente 1</td><td>43        </td><td>15/10/2015</td><td>Tipo 1    </td><td>Ruim      </td></tr>\n",
       "\t<tr><td>Portugal  </td><td>Bruno     </td><td>1.88      </td><td>5001      </td><td>Verde     </td><td>2         </td><td>Paciente 2</td><td>23        </td><td>16/10/2015</td><td>Tipo 2    </td><td>Bom       </td></tr>\n",
       "\t<tr><td>Inglaterra</td><td>Tiago     </td><td>1.76      </td><td>2183      </td><td>azul      </td><td>2         </td><td>Paciente 2</td><td>23        </td><td>16/10/2015</td><td>Tipo 2    </td><td>Bom       </td></tr>\n",
       "\t<tr><td>Irlanda   </td><td>Amanda    </td><td>1.53      </td><td>4702      </td><td>azul      </td><td>2         </td><td>Paciente 2</td><td>23        </td><td>16/10/2015</td><td>Tipo 2    </td><td>Bom       </td></tr>\n",
       "\t<tr><td>Egito     </td><td>Bianca    </td><td>1.69      </td><td>7965      </td><td>castanho  </td><td>2         </td><td>Paciente 2</td><td>23        </td><td>16/10/2015</td><td>Tipo 2    </td><td>Bom       </td></tr>\n",
       "\t<tr><td>Brasil    </td><td>Marta     </td><td>1.68      </td><td>8890      </td><td>castanho  </td><td>2         </td><td>Paciente 2</td><td>23        </td><td>16/10/2015</td><td>Tipo 2    </td><td>Bom       </td></tr>\n",
       "\t<tr><td>Portugal  </td><td>Bruno     </td><td>1.88      </td><td>5001      </td><td>Verde     </td><td>3         </td><td>Paciente 3</td><td>56        </td><td>23/10/2015</td><td>Tipo 2    </td><td>Bom       </td></tr>\n",
       "\t<tr><td>Inglaterra</td><td>Tiago     </td><td>1.76      </td><td>2183      </td><td>azul      </td><td>3         </td><td>Paciente 3</td><td>56        </td><td>23/10/2015</td><td>Tipo 2    </td><td>Bom       </td></tr>\n",
       "\t<tr><td>Irlanda   </td><td>Amanda    </td><td>1.53      </td><td>4702      </td><td>azul      </td><td>3         </td><td>Paciente 3</td><td>56        </td><td>23/10/2015</td><td>Tipo 2    </td><td>Bom       </td></tr>\n",
       "\t<tr><td>Egito     </td><td>Bianca    </td><td>1.69      </td><td>7965      </td><td>castanho  </td><td>3         </td><td>Paciente 3</td><td>56        </td><td>23/10/2015</td><td>Tipo 2    </td><td>Bom       </td></tr>\n",
       "\t<tr><td>Brasil    </td><td>Marta     </td><td>1.68      </td><td>8890      </td><td>castanho  </td><td>3         </td><td>Paciente 3</td><td>56        </td><td>23/10/2015</td><td>Tipo 2    </td><td>Bom       </td></tr>\n",
       "\t<tr><td>Portugal  </td><td>Bruno     </td><td>1.88      </td><td>5001      </td><td>Verde     </td><td>4         </td><td>Paciente 4</td><td>34        </td><td>24/10/2015</td><td>Tipo 1    </td><td>Ruim      </td></tr>\n",
       "\t<tr><td>Inglaterra</td><td>Tiago     </td><td>1.76      </td><td>2183      </td><td>azul      </td><td>4         </td><td>Paciente 4</td><td>34        </td><td>24/10/2015</td><td>Tipo 1    </td><td>Ruim      </td></tr>\n",
       "\t<tr><td>Irlanda   </td><td>Amanda    </td><td>1.53      </td><td>4702      </td><td>azul      </td><td>4         </td><td>Paciente 4</td><td>34        </td><td>24/10/2015</td><td>Tipo 1    </td><td>Ruim      </td></tr>\n",
       "\t<tr><td>Egito     </td><td>Bianca    </td><td>1.69      </td><td>7965      </td><td>castanho  </td><td>4         </td><td>Paciente 4</td><td>34        </td><td>24/10/2015</td><td>Tipo 1    </td><td>Ruim      </td></tr>\n",
       "\t<tr><td>Brasil    </td><td>Marta     </td><td>1.68      </td><td>8890      </td><td>castanho  </td><td>4         </td><td>Paciente 4</td><td>34        </td><td>24/10/2015</td><td>Tipo 1    </td><td>Ruim      </td></tr>\n",
       "\t<tr><td>Portugal  </td><td>Bruno     </td><td>1.88      </td><td>5001      </td><td>Verde     </td><td>5         </td><td>Paciente 5</td><td>38        </td><td>31/10/2015</td><td>Tipo 1    </td><td>Medio     </td></tr>\n",
       "\t<tr><td>Inglaterra</td><td>Tiago     </td><td>1.76      </td><td>2183      </td><td>azul      </td><td>5         </td><td>Paciente 5</td><td>38        </td><td>31/10/2015</td><td>Tipo 1    </td><td>Medio     </td></tr>\n",
       "\t<tr><td>Irlanda   </td><td>Amanda    </td><td>1.53      </td><td>4702      </td><td>azul      </td><td>5         </td><td>Paciente 5</td><td>38        </td><td>31/10/2015</td><td>Tipo 1    </td><td>Medio     </td></tr>\n",
       "\t<tr><td>Egito     </td><td>Bianca    </td><td>1.69      </td><td>7965      </td><td>castanho  </td><td>5         </td><td>Paciente 5</td><td>38        </td><td>31/10/2015</td><td>Tipo 1    </td><td>Medio     </td></tr>\n",
       "\t<tr><td>Brasil    </td><td>Marta     </td><td>1.68      </td><td>8890      </td><td>castanho  </td><td>5         </td><td>Paciente 5</td><td>38        </td><td>31/10/2015</td><td>Tipo 1    </td><td>Medio     </td></tr>\n",
       "\t<tr><td>Portugal  </td><td>Bruno     </td><td>1.88      </td><td>5001      </td><td>Verde     </td><td>6         </td><td>Paciente 6</td><td>37        </td><td>28/10/2015</td><td>Tipo 1    </td><td>Bom       </td></tr>\n",
       "\t<tr><td>Inglaterra</td><td>Tiago     </td><td>1.76      </td><td>2183      </td><td>azul      </td><td>6         </td><td>Paciente 6</td><td>37        </td><td>28/10/2015</td><td>Tipo 1    </td><td>Bom       </td></tr>\n",
       "\t<tr><td>Irlanda   </td><td>Amanda    </td><td>1.53      </td><td>4702      </td><td>azul      </td><td>6         </td><td>Paciente 6</td><td>37        </td><td>28/10/2015</td><td>Tipo 1    </td><td>Bom       </td></tr>\n",
       "\t<tr><td>Egito     </td><td>Bianca    </td><td>1.69      </td><td>7965      </td><td>castanho  </td><td>6         </td><td>Paciente 6</td><td>37        </td><td>28/10/2015</td><td>Tipo 1    </td><td>Bom       </td></tr>\n",
       "\t<tr><td>Brasil    </td><td>Marta     </td><td>1.68      </td><td>8890      </td><td>castanho  </td><td>6         </td><td>Paciente 6</td><td>37        </td><td>28/10/2015</td><td>Tipo 1    </td><td>Bom       </td></tr>\n",
       "\t<tr><td>Portugal  </td><td>Bruno     </td><td>1.88      </td><td>5001      </td><td>Verde     </td><td>7         </td><td>Paciente 7</td><td>41        </td><td>27/10/2015</td><td>Tipo 1    </td><td>Ruim      </td></tr>\n",
       "\t<tr><td>Inglaterra</td><td>Tiago     </td><td>1.76      </td><td>2183      </td><td>azul      </td><td>7         </td><td>Paciente 7</td><td>41        </td><td>27/10/2015</td><td>Tipo 1    </td><td>Ruim      </td></tr>\n",
       "\t<tr><td>Irlanda   </td><td>Amanda    </td><td>1.53      </td><td>4702      </td><td>azul      </td><td>7         </td><td>Paciente 7</td><td>41        </td><td>27/10/2015</td><td>Tipo 1    </td><td>Ruim      </td></tr>\n",
       "\t<tr><td>Egito     </td><td>Bianca    </td><td>1.69      </td><td>7965      </td><td>castanho  </td><td>7         </td><td>Paciente 7</td><td>41        </td><td>27/10/2015</td><td>Tipo 1    </td><td>Ruim      </td></tr>\n",
       "\t<tr><td>Brasil    </td><td>Marta     </td><td>1.68      </td><td>8890      </td><td>castanho  </td><td>7         </td><td>Paciente 7</td><td>41        </td><td>27/10/2015</td><td>Tipo 1    </td><td>Ruim      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllll}\n",
       " var 1 & var 2 & var 3 & var 4 & var 5 & ID & Nome & Idade & Admdate & Diabete & Status\\\\\n",
       "\\hline\n",
       "\t Portugal   & Bruno      & 1.88       & 5001       & Verde      & 1          & Paciente 1 & 43         & 15/10/2015 & Tipo 1     & Ruim      \\\\\n",
       "\t Inglaterra & Tiago      & 1.76       & 2183       & azul       & 1          & Paciente 1 & 43         & 15/10/2015 & Tipo 1     & Ruim      \\\\\n",
       "\t Irlanda    & Amanda     & 1.53       & 4702       & azul       & 1          & Paciente 1 & 43         & 15/10/2015 & Tipo 1     & Ruim      \\\\\n",
       "\t Egito      & Bianca     & 1.69       & 7965       & castanho   & 1          & Paciente 1 & 43         & 15/10/2015 & Tipo 1     & Ruim      \\\\\n",
       "\t Brasil     & Marta      & 1.68       & 8890       & castanho   & 1          & Paciente 1 & 43         & 15/10/2015 & Tipo 1     & Ruim      \\\\\n",
       "\t Portugal   & Bruno      & 1.88       & 5001       & Verde      & 2          & Paciente 2 & 23         & 16/10/2015 & Tipo 2     & Bom       \\\\\n",
       "\t Inglaterra & Tiago      & 1.76       & 2183       & azul       & 2          & Paciente 2 & 23         & 16/10/2015 & Tipo 2     & Bom       \\\\\n",
       "\t Irlanda    & Amanda     & 1.53       & 4702       & azul       & 2          & Paciente 2 & 23         & 16/10/2015 & Tipo 2     & Bom       \\\\\n",
       "\t Egito      & Bianca     & 1.69       & 7965       & castanho   & 2          & Paciente 2 & 23         & 16/10/2015 & Tipo 2     & Bom       \\\\\n",
       "\t Brasil     & Marta      & 1.68       & 8890       & castanho   & 2          & Paciente 2 & 23         & 16/10/2015 & Tipo 2     & Bom       \\\\\n",
       "\t Portugal   & Bruno      & 1.88       & 5001       & Verde      & 3          & Paciente 3 & 56         & 23/10/2015 & Tipo 2     & Bom       \\\\\n",
       "\t Inglaterra & Tiago      & 1.76       & 2183       & azul       & 3          & Paciente 3 & 56         & 23/10/2015 & Tipo 2     & Bom       \\\\\n",
       "\t Irlanda    & Amanda     & 1.53       & 4702       & azul       & 3          & Paciente 3 & 56         & 23/10/2015 & Tipo 2     & Bom       \\\\\n",
       "\t Egito      & Bianca     & 1.69       & 7965       & castanho   & 3          & Paciente 3 & 56         & 23/10/2015 & Tipo 2     & Bom       \\\\\n",
       "\t Brasil     & Marta      & 1.68       & 8890       & castanho   & 3          & Paciente 3 & 56         & 23/10/2015 & Tipo 2     & Bom       \\\\\n",
       "\t Portugal   & Bruno      & 1.88       & 5001       & Verde      & 4          & Paciente 4 & 34         & 24/10/2015 & Tipo 1     & Ruim      \\\\\n",
       "\t Inglaterra & Tiago      & 1.76       & 2183       & azul       & 4          & Paciente 4 & 34         & 24/10/2015 & Tipo 1     & Ruim      \\\\\n",
       "\t Irlanda    & Amanda     & 1.53       & 4702       & azul       & 4          & Paciente 4 & 34         & 24/10/2015 & Tipo 1     & Ruim      \\\\\n",
       "\t Egito      & Bianca     & 1.69       & 7965       & castanho   & 4          & Paciente 4 & 34         & 24/10/2015 & Tipo 1     & Ruim      \\\\\n",
       "\t Brasil     & Marta      & 1.68       & 8890       & castanho   & 4          & Paciente 4 & 34         & 24/10/2015 & Tipo 1     & Ruim      \\\\\n",
       "\t Portugal   & Bruno      & 1.88       & 5001       & Verde      & 5          & Paciente 5 & 38         & 31/10/2015 & Tipo 1     & Medio     \\\\\n",
       "\t Inglaterra & Tiago      & 1.76       & 2183       & azul       & 5          & Paciente 5 & 38         & 31/10/2015 & Tipo 1     & Medio     \\\\\n",
       "\t Irlanda    & Amanda     & 1.53       & 4702       & azul       & 5          & Paciente 5 & 38         & 31/10/2015 & Tipo 1     & Medio     \\\\\n",
       "\t Egito      & Bianca     & 1.69       & 7965       & castanho   & 5          & Paciente 5 & 38         & 31/10/2015 & Tipo 1     & Medio     \\\\\n",
       "\t Brasil     & Marta      & 1.68       & 8890       & castanho   & 5          & Paciente 5 & 38         & 31/10/2015 & Tipo 1     & Medio     \\\\\n",
       "\t Portugal   & Bruno      & 1.88       & 5001       & Verde      & 6          & Paciente 6 & 37         & 28/10/2015 & Tipo 1     & Bom       \\\\\n",
       "\t Inglaterra & Tiago      & 1.76       & 2183       & azul       & 6          & Paciente 6 & 37         & 28/10/2015 & Tipo 1     & Bom       \\\\\n",
       "\t Irlanda    & Amanda     & 1.53       & 4702       & azul       & 6          & Paciente 6 & 37         & 28/10/2015 & Tipo 1     & Bom       \\\\\n",
       "\t Egito      & Bianca     & 1.69       & 7965       & castanho   & 6          & Paciente 6 & 37         & 28/10/2015 & Tipo 1     & Bom       \\\\\n",
       "\t Brasil     & Marta      & 1.68       & 8890       & castanho   & 6          & Paciente 6 & 37         & 28/10/2015 & Tipo 1     & Bom       \\\\\n",
       "\t Portugal   & Bruno      & 1.88       & 5001       & Verde      & 7          & Paciente 7 & 41         & 27/10/2015 & Tipo 1     & Ruim      \\\\\n",
       "\t Inglaterra & Tiago      & 1.76       & 2183       & azul       & 7          & Paciente 7 & 41         & 27/10/2015 & Tipo 1     & Ruim      \\\\\n",
       "\t Irlanda    & Amanda     & 1.53       & 4702       & azul       & 7          & Paciente 7 & 41         & 27/10/2015 & Tipo 1     & Ruim      \\\\\n",
       "\t Egito      & Bianca     & 1.69       & 7965       & castanho   & 7          & Paciente 7 & 41         & 27/10/2015 & Tipo 1     & Ruim      \\\\\n",
       "\t Brasil     & Marta      & 1.68       & 8890       & castanho   & 7          & Paciente 7 & 41         & 27/10/2015 & Tipo 1     & Ruim      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "var 1 | var 2 | var 3 | var 4 | var 5 | ID | Nome | Idade | Admdate | Diabete | Status | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| Portugal   | Bruno      | 1.88       | 5001       | Verde      | 1          | Paciente 1 | 43         | 15/10/2015 | Tipo 1     | Ruim       | \n",
       "| Inglaterra | Tiago      | 1.76       | 2183       | azul       | 1          | Paciente 1 | 43         | 15/10/2015 | Tipo 1     | Ruim       | \n",
       "| Irlanda    | Amanda     | 1.53       | 4702       | azul       | 1          | Paciente 1 | 43         | 15/10/2015 | Tipo 1     | Ruim       | \n",
       "| Egito      | Bianca     | 1.69       | 7965       | castanho   | 1          | Paciente 1 | 43         | 15/10/2015 | Tipo 1     | Ruim       | \n",
       "| Brasil     | Marta      | 1.68       | 8890       | castanho   | 1          | Paciente 1 | 43         | 15/10/2015 | Tipo 1     | Ruim       | \n",
       "| Portugal   | Bruno      | 1.88       | 5001       | Verde      | 2          | Paciente 2 | 23         | 16/10/2015 | Tipo 2     | Bom        | \n",
       "| Inglaterra | Tiago      | 1.76       | 2183       | azul       | 2          | Paciente 2 | 23         | 16/10/2015 | Tipo 2     | Bom        | \n",
       "| Irlanda    | Amanda     | 1.53       | 4702       | azul       | 2          | Paciente 2 | 23         | 16/10/2015 | Tipo 2     | Bom        | \n",
       "| Egito      | Bianca     | 1.69       | 7965       | castanho   | 2          | Paciente 2 | 23         | 16/10/2015 | Tipo 2     | Bom        | \n",
       "| Brasil     | Marta      | 1.68       | 8890       | castanho   | 2          | Paciente 2 | 23         | 16/10/2015 | Tipo 2     | Bom        | \n",
       "| Portugal   | Bruno      | 1.88       | 5001       | Verde      | 3          | Paciente 3 | 56         | 23/10/2015 | Tipo 2     | Bom        | \n",
       "| Inglaterra | Tiago      | 1.76       | 2183       | azul       | 3          | Paciente 3 | 56         | 23/10/2015 | Tipo 2     | Bom        | \n",
       "| Irlanda    | Amanda     | 1.53       | 4702       | azul       | 3          | Paciente 3 | 56         | 23/10/2015 | Tipo 2     | Bom        | \n",
       "| Egito      | Bianca     | 1.69       | 7965       | castanho   | 3          | Paciente 3 | 56         | 23/10/2015 | Tipo 2     | Bom        | \n",
       "| Brasil     | Marta      | 1.68       | 8890       | castanho   | 3          | Paciente 3 | 56         | 23/10/2015 | Tipo 2     | Bom        | \n",
       "| Portugal   | Bruno      | 1.88       | 5001       | Verde      | 4          | Paciente 4 | 34         | 24/10/2015 | Tipo 1     | Ruim       | \n",
       "| Inglaterra | Tiago      | 1.76       | 2183       | azul       | 4          | Paciente 4 | 34         | 24/10/2015 | Tipo 1     | Ruim       | \n",
       "| Irlanda    | Amanda     | 1.53       | 4702       | azul       | 4          | Paciente 4 | 34         | 24/10/2015 | Tipo 1     | Ruim       | \n",
       "| Egito      | Bianca     | 1.69       | 7965       | castanho   | 4          | Paciente 4 | 34         | 24/10/2015 | Tipo 1     | Ruim       | \n",
       "| Brasil     | Marta      | 1.68       | 8890       | castanho   | 4          | Paciente 4 | 34         | 24/10/2015 | Tipo 1     | Ruim       | \n",
       "| Portugal   | Bruno      | 1.88       | 5001       | Verde      | 5          | Paciente 5 | 38         | 31/10/2015 | Tipo 1     | Medio      | \n",
       "| Inglaterra | Tiago      | 1.76       | 2183       | azul       | 5          | Paciente 5 | 38         | 31/10/2015 | Tipo 1     | Medio      | \n",
       "| Irlanda    | Amanda     | 1.53       | 4702       | azul       | 5          | Paciente 5 | 38         | 31/10/2015 | Tipo 1     | Medio      | \n",
       "| Egito      | Bianca     | 1.69       | 7965       | castanho   | 5          | Paciente 5 | 38         | 31/10/2015 | Tipo 1     | Medio      | \n",
       "| Brasil     | Marta      | 1.68       | 8890       | castanho   | 5          | Paciente 5 | 38         | 31/10/2015 | Tipo 1     | Medio      | \n",
       "| Portugal   | Bruno      | 1.88       | 5001       | Verde      | 6          | Paciente 6 | 37         | 28/10/2015 | Tipo 1     | Bom        | \n",
       "| Inglaterra | Tiago      | 1.76       | 2183       | azul       | 6          | Paciente 6 | 37         | 28/10/2015 | Tipo 1     | Bom        | \n",
       "| Irlanda    | Amanda     | 1.53       | 4702       | azul       | 6          | Paciente 6 | 37         | 28/10/2015 | Tipo 1     | Bom        | \n",
       "| Egito      | Bianca     | 1.69       | 7965       | castanho   | 6          | Paciente 6 | 37         | 28/10/2015 | Tipo 1     | Bom        | \n",
       "| Brasil     | Marta      | 1.68       | 8890       | castanho   | 6          | Paciente 6 | 37         | 28/10/2015 | Tipo 1     | Bom        | \n",
       "| Portugal   | Bruno      | 1.88       | 5001       | Verde      | 7          | Paciente 7 | 41         | 27/10/2015 | Tipo 1     | Ruim       | \n",
       "| Inglaterra | Tiago      | 1.76       | 2183       | azul       | 7          | Paciente 7 | 41         | 27/10/2015 | Tipo 1     | Ruim       | \n",
       "| Irlanda    | Amanda     | 1.53       | 4702       | azul       | 7          | Paciente 7 | 41         | 27/10/2015 | Tipo 1     | Ruim       | \n",
       "| Egito      | Bianca     | 1.69       | 7965       | castanho   | 7          | Paciente 7 | 41         | 27/10/2015 | Tipo 1     | Ruim       | \n",
       "| Brasil     | Marta      | 1.68       | 8890       | castanho   | 7          | Paciente 7 | 41         | 27/10/2015 | Tipo 1     | Ruim       | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   var 1      var 2  var 3 var 4 var 5    ID Nome       Idade Admdate   \n",
       "1  Portugal   Bruno  1.88  5001  Verde    1  Paciente 1 43    15/10/2015\n",
       "2  Inglaterra Tiago  1.76  2183  azul     1  Paciente 1 43    15/10/2015\n",
       "3  Irlanda    Amanda 1.53  4702  azul     1  Paciente 1 43    15/10/2015\n",
       "4  Egito      Bianca 1.69  7965  castanho 1  Paciente 1 43    15/10/2015\n",
       "5  Brasil     Marta  1.68  8890  castanho 1  Paciente 1 43    15/10/2015\n",
       "6  Portugal   Bruno  1.88  5001  Verde    2  Paciente 2 23    16/10/2015\n",
       "7  Inglaterra Tiago  1.76  2183  azul     2  Paciente 2 23    16/10/2015\n",
       "8  Irlanda    Amanda 1.53  4702  azul     2  Paciente 2 23    16/10/2015\n",
       "9  Egito      Bianca 1.69  7965  castanho 2  Paciente 2 23    16/10/2015\n",
       "10 Brasil     Marta  1.68  8890  castanho 2  Paciente 2 23    16/10/2015\n",
       "11 Portugal   Bruno  1.88  5001  Verde    3  Paciente 3 56    23/10/2015\n",
       "12 Inglaterra Tiago  1.76  2183  azul     3  Paciente 3 56    23/10/2015\n",
       "13 Irlanda    Amanda 1.53  4702  azul     3  Paciente 3 56    23/10/2015\n",
       "14 Egito      Bianca 1.69  7965  castanho 3  Paciente 3 56    23/10/2015\n",
       "15 Brasil     Marta  1.68  8890  castanho 3  Paciente 3 56    23/10/2015\n",
       "16 Portugal   Bruno  1.88  5001  Verde    4  Paciente 4 34    24/10/2015\n",
       "17 Inglaterra Tiago  1.76  2183  azul     4  Paciente 4 34    24/10/2015\n",
       "18 Irlanda    Amanda 1.53  4702  azul     4  Paciente 4 34    24/10/2015\n",
       "19 Egito      Bianca 1.69  7965  castanho 4  Paciente 4 34    24/10/2015\n",
       "20 Brasil     Marta  1.68  8890  castanho 4  Paciente 4 34    24/10/2015\n",
       "21 Portugal   Bruno  1.88  5001  Verde    5  Paciente 5 38    31/10/2015\n",
       "22 Inglaterra Tiago  1.76  2183  azul     5  Paciente 5 38    31/10/2015\n",
       "23 Irlanda    Amanda 1.53  4702  azul     5  Paciente 5 38    31/10/2015\n",
       "24 Egito      Bianca 1.69  7965  castanho 5  Paciente 5 38    31/10/2015\n",
       "25 Brasil     Marta  1.68  8890  castanho 5  Paciente 5 38    31/10/2015\n",
       "26 Portugal   Bruno  1.88  5001  Verde    6  Paciente 6 37    28/10/2015\n",
       "27 Inglaterra Tiago  1.76  2183  azul     6  Paciente 6 37    28/10/2015\n",
       "28 Irlanda    Amanda 1.53  4702  azul     6  Paciente 6 37    28/10/2015\n",
       "29 Egito      Bianca 1.69  7965  castanho 6  Paciente 6 37    28/10/2015\n",
       "30 Brasil     Marta  1.68  8890  castanho 6  Paciente 6 37    28/10/2015\n",
       "31 Portugal   Bruno  1.88  5001  Verde    7  Paciente 7 41    27/10/2015\n",
       "32 Inglaterra Tiago  1.76  2183  azul     7  Paciente 7 41    27/10/2015\n",
       "33 Irlanda    Amanda 1.53  4702  azul     7  Paciente 7 41    27/10/2015\n",
       "34 Egito      Bianca 1.69  7965  castanho 7  Paciente 7 41    27/10/2015\n",
       "35 Brasil     Marta  1.68  8890  castanho 7  Paciente 7 41    27/10/2015\n",
       "   Diabete Status\n",
       "1  Tipo 1  Ruim  \n",
       "2  Tipo 1  Ruim  \n",
       "3  Tipo 1  Ruim  \n",
       "4  Tipo 1  Ruim  \n",
       "5  Tipo 1  Ruim  \n",
       "6  Tipo 2  Bom   \n",
       "7  Tipo 2  Bom   \n",
       "8  Tipo 2  Bom   \n",
       "9  Tipo 2  Bom   \n",
       "10 Tipo 2  Bom   \n",
       "11 Tipo 2  Bom   \n",
       "12 Tipo 2  Bom   \n",
       "13 Tipo 2  Bom   \n",
       "14 Tipo 2  Bom   \n",
       "15 Tipo 2  Bom   \n",
       "16 Tipo 1  Ruim  \n",
       "17 Tipo 1  Ruim  \n",
       "18 Tipo 1  Ruim  \n",
       "19 Tipo 1  Ruim  \n",
       "20 Tipo 1  Ruim  \n",
       "21 Tipo 1  Medio \n",
       "22 Tipo 1  Medio \n",
       "23 Tipo 1  Medio \n",
       "24 Tipo 1  Medio \n",
       "25 Tipo 1  Medio \n",
       "26 Tipo 1  Bom   \n",
       "27 Tipo 1  Bom   \n",
       "28 Tipo 1  Bom   \n",
       "29 Tipo 1  Bom   \n",
       "30 Tipo 1  Bom   \n",
       "31 Tipo 1  Ruim  \n",
       "32 Tipo 1  Ruim  \n",
       "33 Tipo 1  Ruim  \n",
       "34 Tipo 1  Ruim  \n",
       "35 Tipo 1  Ruim  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_final <- merge(pesq, pacientes)\n",
    "dataset_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>mpg</th><th scope=col>cyl</th><th scope=col>disp</th><th scope=col>hp</th><th scope=col>drat</th><th scope=col>wt</th><th scope=col>qsec</th><th scope=col>vs</th><th scope=col>am</th><th scope=col>gear</th><th scope=col>carb</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Mazda RX4</th><td>21.0 </td><td>6    </td><td>160.0</td><td>110  </td><td>3.90 </td><td>2.620</td><td>16.46</td><td>0    </td><td>1    </td><td>4    </td><td>4    </td></tr>\n",
       "\t<tr><th scope=row>Mazda RX4 Wag</th><td>21.0 </td><td>6    </td><td>160.0</td><td>110  </td><td>3.90 </td><td>2.875</td><td>17.02</td><td>0    </td><td>1    </td><td>4    </td><td>4    </td></tr>\n",
       "\t<tr><th scope=row>Datsun 710</th><td>22.8 </td><td>4    </td><td>108.0</td><td> 93  </td><td>3.85 </td><td>2.320</td><td>18.61</td><td>1    </td><td>1    </td><td>4    </td><td>1    </td></tr>\n",
       "\t<tr><th scope=row>Hornet 4 Drive</th><td>21.4 </td><td>6    </td><td>258.0</td><td>110  </td><td>3.08 </td><td>3.215</td><td>19.44</td><td>1    </td><td>0    </td><td>3    </td><td>1    </td></tr>\n",
       "\t<tr><th scope=row>Hornet Sportabout</th><td>18.7 </td><td>8    </td><td>360.0</td><td>175  </td><td>3.15 </td><td>3.440</td><td>17.02</td><td>0    </td><td>0    </td><td>3    </td><td>2    </td></tr>\n",
       "\t<tr><th scope=row>Valiant</th><td>18.1 </td><td>6    </td><td>225.0</td><td>105  </td><td>2.76 </td><td>3.460</td><td>20.22</td><td>1    </td><td>0    </td><td>3    </td><td>1    </td></tr>\n",
       "\t<tr><th scope=row>Duster 360</th><td>14.3 </td><td>8    </td><td>360.0</td><td>245  </td><td>3.21 </td><td>3.570</td><td>15.84</td><td>0    </td><td>0    </td><td>3    </td><td>4    </td></tr>\n",
       "\t<tr><th scope=row>Merc 240D</th><td>24.4 </td><td>4    </td><td>146.7</td><td> 62  </td><td>3.69 </td><td>3.190</td><td>20.00</td><td>1    </td><td>0    </td><td>4    </td><td>2    </td></tr>\n",
       "\t<tr><th scope=row>Merc 230</th><td>22.8 </td><td>4    </td><td>140.8</td><td> 95  </td><td>3.92 </td><td>3.150</td><td>22.90</td><td>1    </td><td>0    </td><td>4    </td><td>2    </td></tr>\n",
       "\t<tr><th scope=row>Merc 280</th><td>19.2 </td><td>6    </td><td>167.6</td><td>123  </td><td>3.92 </td><td>3.440</td><td>18.30</td><td>1    </td><td>0    </td><td>4    </td><td>4    </td></tr>\n",
       "\t<tr><th scope=row>Merc 280C</th><td>17.8 </td><td>6    </td><td>167.6</td><td>123  </td><td>3.92 </td><td>3.440</td><td>18.90</td><td>1    </td><td>0    </td><td>4    </td><td>4    </td></tr>\n",
       "\t<tr><th scope=row>Merc 450SE</th><td>16.4 </td><td>8    </td><td>275.8</td><td>180  </td><td>3.07 </td><td>4.070</td><td>17.40</td><td>0    </td><td>0    </td><td>3    </td><td>3    </td></tr>\n",
       "\t<tr><th scope=row>Merc 450SL</th><td>17.3 </td><td>8    </td><td>275.8</td><td>180  </td><td>3.07 </td><td>3.730</td><td>17.60</td><td>0    </td><td>0    </td><td>3    </td><td>3    </td></tr>\n",
       "\t<tr><th scope=row>Merc 450SLC</th><td>15.2 </td><td>8    </td><td>275.8</td><td>180  </td><td>3.07 </td><td>3.780</td><td>18.00</td><td>0    </td><td>0    </td><td>3    </td><td>3    </td></tr>\n",
       "\t<tr><th scope=row>Cadillac Fleetwood</th><td>10.4 </td><td>8    </td><td>472.0</td><td>205  </td><td>2.93 </td><td>5.250</td><td>17.98</td><td>0    </td><td>0    </td><td>3    </td><td>4    </td></tr>\n",
       "\t<tr><th scope=row>Lincoln Continental</th><td>10.4 </td><td>8    </td><td>460.0</td><td>215  </td><td>3.00 </td><td>5.424</td><td>17.82</td><td>0    </td><td>0    </td><td>3    </td><td>4    </td></tr>\n",
       "\t<tr><th scope=row>Chrysler Imperial</th><td>14.7 </td><td>8    </td><td>440.0</td><td>230  </td><td>3.23 </td><td>5.345</td><td>17.42</td><td>0    </td><td>0    </td><td>3    </td><td>4    </td></tr>\n",
       "\t<tr><th scope=row>Fiat 128</th><td>32.4 </td><td>4    </td><td> 78.7</td><td> 66  </td><td>4.08 </td><td>2.200</td><td>19.47</td><td>1    </td><td>1    </td><td>4    </td><td>1    </td></tr>\n",
       "\t<tr><th scope=row>Honda Civic</th><td>30.4 </td><td>4    </td><td> 75.7</td><td> 52  </td><td>4.93 </td><td>1.615</td><td>18.52</td><td>1    </td><td>1    </td><td>4    </td><td>2    </td></tr>\n",
       "\t<tr><th scope=row>Toyota Corolla</th><td>33.9 </td><td>4    </td><td> 71.1</td><td> 65  </td><td>4.22 </td><td>1.835</td><td>19.90</td><td>1    </td><td>1    </td><td>4    </td><td>1    </td></tr>\n",
       "\t<tr><th scope=row>Toyota Corona</th><td>21.5 </td><td>4    </td><td>120.1</td><td> 97  </td><td>3.70 </td><td>2.465</td><td>20.01</td><td>1    </td><td>0    </td><td>3    </td><td>1    </td></tr>\n",
       "\t<tr><th scope=row>Dodge Challenger</th><td>15.5 </td><td>8    </td><td>318.0</td><td>150  </td><td>2.76 </td><td>3.520</td><td>16.87</td><td>0    </td><td>0    </td><td>3    </td><td>2    </td></tr>\n",
       "\t<tr><th scope=row>AMC Javelin</th><td>15.2 </td><td>8    </td><td>304.0</td><td>150  </td><td>3.15 </td><td>3.435</td><td>17.30</td><td>0    </td><td>0    </td><td>3    </td><td>2    </td></tr>\n",
       "\t<tr><th scope=row>Camaro Z28</th><td>13.3 </td><td>8    </td><td>350.0</td><td>245  </td><td>3.73 </td><td>3.840</td><td>15.41</td><td>0    </td><td>0    </td><td>3    </td><td>4    </td></tr>\n",
       "\t<tr><th scope=row>Pontiac Firebird</th><td>19.2 </td><td>8    </td><td>400.0</td><td>175  </td><td>3.08 </td><td>3.845</td><td>17.05</td><td>0    </td><td>0    </td><td>3    </td><td>2    </td></tr>\n",
       "\t<tr><th scope=row>Fiat X1-9</th><td>27.3 </td><td>4    </td><td> 79.0</td><td> 66  </td><td>4.08 </td><td>1.935</td><td>18.90</td><td>1    </td><td>1    </td><td>4    </td><td>1    </td></tr>\n",
       "\t<tr><th scope=row>Porsche 914-2</th><td>26.0 </td><td>4    </td><td>120.3</td><td> 91  </td><td>4.43 </td><td>2.140</td><td>16.70</td><td>0    </td><td>1    </td><td>5    </td><td>2    </td></tr>\n",
       "\t<tr><th scope=row>Lotus Europa</th><td>30.4 </td><td>4    </td><td> 95.1</td><td>113  </td><td>3.77 </td><td>1.513</td><td>16.90</td><td>1    </td><td>1    </td><td>5    </td><td>2    </td></tr>\n",
       "\t<tr><th scope=row>Ford Pantera L</th><td>15.8 </td><td>8    </td><td>351.0</td><td>264  </td><td>4.22 </td><td>3.170</td><td>14.50</td><td>0    </td><td>1    </td><td>5    </td><td>4    </td></tr>\n",
       "\t<tr><th scope=row>Ferrari Dino</th><td>19.7 </td><td>6    </td><td>145.0</td><td>175  </td><td>3.62 </td><td>2.770</td><td>15.50</td><td>0    </td><td>1    </td><td>5    </td><td>6    </td></tr>\n",
       "\t<tr><th scope=row>Maserati Bora</th><td>15.0 </td><td>8    </td><td>301.0</td><td>335  </td><td>3.54 </td><td>3.570</td><td>14.60</td><td>0    </td><td>1    </td><td>5    </td><td>8    </td></tr>\n",
       "\t<tr><th scope=row>Volvo 142E</th><td>21.4 </td><td>4    </td><td>121.0</td><td>109  </td><td>4.11 </td><td>2.780</td><td>18.60</td><td>1    </td><td>1    </td><td>4    </td><td>2    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllll}\n",
       "  & mpg & cyl & disp & hp & drat & wt & qsec & vs & am & gear & carb\\\\\n",
       "\\hline\n",
       "\tMazda RX4 & 21.0  & 6     & 160.0 & 110   & 3.90  & 2.620 & 16.46 & 0     & 1     & 4     & 4    \\\\\n",
       "\tMazda RX4 Wag & 21.0  & 6     & 160.0 & 110   & 3.90  & 2.875 & 17.02 & 0     & 1     & 4     & 4    \\\\\n",
       "\tDatsun 710 & 22.8  & 4     & 108.0 &  93   & 3.85  & 2.320 & 18.61 & 1     & 1     & 4     & 1    \\\\\n",
       "\tHornet 4 Drive & 21.4  & 6     & 258.0 & 110   & 3.08  & 3.215 & 19.44 & 1     & 0     & 3     & 1    \\\\\n",
       "\tHornet Sportabout & 18.7  & 8     & 360.0 & 175   & 3.15  & 3.440 & 17.02 & 0     & 0     & 3     & 2    \\\\\n",
       "\tValiant & 18.1  & 6     & 225.0 & 105   & 2.76  & 3.460 & 20.22 & 1     & 0     & 3     & 1    \\\\\n",
       "\tDuster 360 & 14.3  & 8     & 360.0 & 245   & 3.21  & 3.570 & 15.84 & 0     & 0     & 3     & 4    \\\\\n",
       "\tMerc 240D & 24.4  & 4     & 146.7 &  62   & 3.69  & 3.190 & 20.00 & 1     & 0     & 4     & 2    \\\\\n",
       "\tMerc 230 & 22.8  & 4     & 140.8 &  95   & 3.92  & 3.150 & 22.90 & 1     & 0     & 4     & 2    \\\\\n",
       "\tMerc 280 & 19.2  & 6     & 167.6 & 123   & 3.92  & 3.440 & 18.30 & 1     & 0     & 4     & 4    \\\\\n",
       "\tMerc 280C & 17.8  & 6     & 167.6 & 123   & 3.92  & 3.440 & 18.90 & 1     & 0     & 4     & 4    \\\\\n",
       "\tMerc 450SE & 16.4  & 8     & 275.8 & 180   & 3.07  & 4.070 & 17.40 & 0     & 0     & 3     & 3    \\\\\n",
       "\tMerc 450SL & 17.3  & 8     & 275.8 & 180   & 3.07  & 3.730 & 17.60 & 0     & 0     & 3     & 3    \\\\\n",
       "\tMerc 450SLC & 15.2  & 8     & 275.8 & 180   & 3.07  & 3.780 & 18.00 & 0     & 0     & 3     & 3    \\\\\n",
       "\tCadillac Fleetwood & 10.4  & 8     & 472.0 & 205   & 2.93  & 5.250 & 17.98 & 0     & 0     & 3     & 4    \\\\\n",
       "\tLincoln Continental & 10.4  & 8     & 460.0 & 215   & 3.00  & 5.424 & 17.82 & 0     & 0     & 3     & 4    \\\\\n",
       "\tChrysler Imperial & 14.7  & 8     & 440.0 & 230   & 3.23  & 5.345 & 17.42 & 0     & 0     & 3     & 4    \\\\\n",
       "\tFiat 128 & 32.4  & 4     &  78.7 &  66   & 4.08  & 2.200 & 19.47 & 1     & 1     & 4     & 1    \\\\\n",
       "\tHonda Civic & 30.4  & 4     &  75.7 &  52   & 4.93  & 1.615 & 18.52 & 1     & 1     & 4     & 2    \\\\\n",
       "\tToyota Corolla & 33.9  & 4     &  71.1 &  65   & 4.22  & 1.835 & 19.90 & 1     & 1     & 4     & 1    \\\\\n",
       "\tToyota Corona & 21.5  & 4     & 120.1 &  97   & 3.70  & 2.465 & 20.01 & 1     & 0     & 3     & 1    \\\\\n",
       "\tDodge Challenger & 15.5  & 8     & 318.0 & 150   & 2.76  & 3.520 & 16.87 & 0     & 0     & 3     & 2    \\\\\n",
       "\tAMC Javelin & 15.2  & 8     & 304.0 & 150   & 3.15  & 3.435 & 17.30 & 0     & 0     & 3     & 2    \\\\\n",
       "\tCamaro Z28 & 13.3  & 8     & 350.0 & 245   & 3.73  & 3.840 & 15.41 & 0     & 0     & 3     & 4    \\\\\n",
       "\tPontiac Firebird & 19.2  & 8     & 400.0 & 175   & 3.08  & 3.845 & 17.05 & 0     & 0     & 3     & 2    \\\\\n",
       "\tFiat X1-9 & 27.3  & 4     &  79.0 &  66   & 4.08  & 1.935 & 18.90 & 1     & 1     & 4     & 1    \\\\\n",
       "\tPorsche 914-2 & 26.0  & 4     & 120.3 &  91   & 4.43  & 2.140 & 16.70 & 0     & 1     & 5     & 2    \\\\\n",
       "\tLotus Europa & 30.4  & 4     &  95.1 & 113   & 3.77  & 1.513 & 16.90 & 1     & 1     & 5     & 2    \\\\\n",
       "\tFord Pantera L & 15.8  & 8     & 351.0 & 264   & 4.22  & 3.170 & 14.50 & 0     & 1     & 5     & 4    \\\\\n",
       "\tFerrari Dino & 19.7  & 6     & 145.0 & 175   & 3.62  & 2.770 & 15.50 & 0     & 1     & 5     & 6    \\\\\n",
       "\tMaserati Bora & 15.0  & 8     & 301.0 & 335   & 3.54  & 3.570 & 14.60 & 0     & 1     & 5     & 8    \\\\\n",
       "\tVolvo 142E & 21.4  & 4     & 121.0 & 109   & 4.11  & 2.780 & 18.60 & 1     & 1     & 4     & 2    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | mpg | cyl | disp | hp | drat | wt | qsec | vs | am | gear | carb | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| Mazda RX4 | 21.0  | 6     | 160.0 | 110   | 3.90  | 2.620 | 16.46 | 0     | 1     | 4     | 4     | \n",
       "| Mazda RX4 Wag | 21.0  | 6     | 160.0 | 110   | 3.90  | 2.875 | 17.02 | 0     | 1     | 4     | 4     | \n",
       "| Datsun 710 | 22.8  | 4     | 108.0 |  93   | 3.85  | 2.320 | 18.61 | 1     | 1     | 4     | 1     | \n",
       "| Hornet 4 Drive | 21.4  | 6     | 258.0 | 110   | 3.08  | 3.215 | 19.44 | 1     | 0     | 3     | 1     | \n",
       "| Hornet Sportabout | 18.7  | 8     | 360.0 | 175   | 3.15  | 3.440 | 17.02 | 0     | 0     | 3     | 2     | \n",
       "| Valiant | 18.1  | 6     | 225.0 | 105   | 2.76  | 3.460 | 20.22 | 1     | 0     | 3     | 1     | \n",
       "| Duster 360 | 14.3  | 8     | 360.0 | 245   | 3.21  | 3.570 | 15.84 | 0     | 0     | 3     | 4     | \n",
       "| Merc 240D | 24.4  | 4     | 146.7 |  62   | 3.69  | 3.190 | 20.00 | 1     | 0     | 4     | 2     | \n",
       "| Merc 230 | 22.8  | 4     | 140.8 |  95   | 3.92  | 3.150 | 22.90 | 1     | 0     | 4     | 2     | \n",
       "| Merc 280 | 19.2  | 6     | 167.6 | 123   | 3.92  | 3.440 | 18.30 | 1     | 0     | 4     | 4     | \n",
       "| Merc 280C | 17.8  | 6     | 167.6 | 123   | 3.92  | 3.440 | 18.90 | 1     | 0     | 4     | 4     | \n",
       "| Merc 450SE | 16.4  | 8     | 275.8 | 180   | 3.07  | 4.070 | 17.40 | 0     | 0     | 3     | 3     | \n",
       "| Merc 450SL | 17.3  | 8     | 275.8 | 180   | 3.07  | 3.730 | 17.60 | 0     | 0     | 3     | 3     | \n",
       "| Merc 450SLC | 15.2  | 8     | 275.8 | 180   | 3.07  | 3.780 | 18.00 | 0     | 0     | 3     | 3     | \n",
       "| Cadillac Fleetwood | 10.4  | 8     | 472.0 | 205   | 2.93  | 5.250 | 17.98 | 0     | 0     | 3     | 4     | \n",
       "| Lincoln Continental | 10.4  | 8     | 460.0 | 215   | 3.00  | 5.424 | 17.82 | 0     | 0     | 3     | 4     | \n",
       "| Chrysler Imperial | 14.7  | 8     | 440.0 | 230   | 3.23  | 5.345 | 17.42 | 0     | 0     | 3     | 4     | \n",
       "| Fiat 128 | 32.4  | 4     |  78.7 |  66   | 4.08  | 2.200 | 19.47 | 1     | 1     | 4     | 1     | \n",
       "| Honda Civic | 30.4  | 4     |  75.7 |  52   | 4.93  | 1.615 | 18.52 | 1     | 1     | 4     | 2     | \n",
       "| Toyota Corolla | 33.9  | 4     |  71.1 |  65   | 4.22  | 1.835 | 19.90 | 1     | 1     | 4     | 1     | \n",
       "| Toyota Corona | 21.5  | 4     | 120.1 |  97   | 3.70  | 2.465 | 20.01 | 1     | 0     | 3     | 1     | \n",
       "| Dodge Challenger | 15.5  | 8     | 318.0 | 150   | 2.76  | 3.520 | 16.87 | 0     | 0     | 3     | 2     | \n",
       "| AMC Javelin | 15.2  | 8     | 304.0 | 150   | 3.15  | 3.435 | 17.30 | 0     | 0     | 3     | 2     | \n",
       "| Camaro Z28 | 13.3  | 8     | 350.0 | 245   | 3.73  | 3.840 | 15.41 | 0     | 0     | 3     | 4     | \n",
       "| Pontiac Firebird | 19.2  | 8     | 400.0 | 175   | 3.08  | 3.845 | 17.05 | 0     | 0     | 3     | 2     | \n",
       "| Fiat X1-9 | 27.3  | 4     |  79.0 |  66   | 4.08  | 1.935 | 18.90 | 1     | 1     | 4     | 1     | \n",
       "| Porsche 914-2 | 26.0  | 4     | 120.3 |  91   | 4.43  | 2.140 | 16.70 | 0     | 1     | 5     | 2     | \n",
       "| Lotus Europa | 30.4  | 4     |  95.1 | 113   | 3.77  | 1.513 | 16.90 | 1     | 1     | 5     | 2     | \n",
       "| Ford Pantera L | 15.8  | 8     | 351.0 | 264   | 4.22  | 3.170 | 14.50 | 0     | 1     | 5     | 4     | \n",
       "| Ferrari Dino | 19.7  | 6     | 145.0 | 175   | 3.62  | 2.770 | 15.50 | 0     | 1     | 5     | 6     | \n",
       "| Maserati Bora | 15.0  | 8     | 301.0 | 335   | 3.54  | 3.570 | 14.60 | 0     | 1     | 5     | 8     | \n",
       "| Volvo 142E | 21.4  | 4     | 121.0 | 109   | 4.11  | 2.780 | 18.60 | 1     | 1     | 4     | 2     | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "                    mpg  cyl disp  hp  drat wt    qsec  vs am gear carb\n",
       "Mazda RX4           21.0 6   160.0 110 3.90 2.620 16.46 0  1  4    4   \n",
       "Mazda RX4 Wag       21.0 6   160.0 110 3.90 2.875 17.02 0  1  4    4   \n",
       "Datsun 710          22.8 4   108.0  93 3.85 2.320 18.61 1  1  4    1   \n",
       "Hornet 4 Drive      21.4 6   258.0 110 3.08 3.215 19.44 1  0  3    1   \n",
       "Hornet Sportabout   18.7 8   360.0 175 3.15 3.440 17.02 0  0  3    2   \n",
       "Valiant             18.1 6   225.0 105 2.76 3.460 20.22 1  0  3    1   \n",
       "Duster 360          14.3 8   360.0 245 3.21 3.570 15.84 0  0  3    4   \n",
       "Merc 240D           24.4 4   146.7  62 3.69 3.190 20.00 1  0  4    2   \n",
       "Merc 230            22.8 4   140.8  95 3.92 3.150 22.90 1  0  4    2   \n",
       "Merc 280            19.2 6   167.6 123 3.92 3.440 18.30 1  0  4    4   \n",
       "Merc 280C           17.8 6   167.6 123 3.92 3.440 18.90 1  0  4    4   \n",
       "Merc 450SE          16.4 8   275.8 180 3.07 4.070 17.40 0  0  3    3   \n",
       "Merc 450SL          17.3 8   275.8 180 3.07 3.730 17.60 0  0  3    3   \n",
       "Merc 450SLC         15.2 8   275.8 180 3.07 3.780 18.00 0  0  3    3   \n",
       "Cadillac Fleetwood  10.4 8   472.0 205 2.93 5.250 17.98 0  0  3    4   \n",
       "Lincoln Continental 10.4 8   460.0 215 3.00 5.424 17.82 0  0  3    4   \n",
       "Chrysler Imperial   14.7 8   440.0 230 3.23 5.345 17.42 0  0  3    4   \n",
       "Fiat 128            32.4 4    78.7  66 4.08 2.200 19.47 1  1  4    1   \n",
       "Honda Civic         30.4 4    75.7  52 4.93 1.615 18.52 1  1  4    2   \n",
       "Toyota Corolla      33.9 4    71.1  65 4.22 1.835 19.90 1  1  4    1   \n",
       "Toyota Corona       21.5 4   120.1  97 3.70 2.465 20.01 1  0  3    1   \n",
       "Dodge Challenger    15.5 8   318.0 150 2.76 3.520 16.87 0  0  3    2   \n",
       "AMC Javelin         15.2 8   304.0 150 3.15 3.435 17.30 0  0  3    2   \n",
       "Camaro Z28          13.3 8   350.0 245 3.73 3.840 15.41 0  0  3    4   \n",
       "Pontiac Firebird    19.2 8   400.0 175 3.08 3.845 17.05 0  0  3    2   \n",
       "Fiat X1-9           27.3 4    79.0  66 4.08 1.935 18.90 1  1  4    1   \n",
       "Porsche 914-2       26.0 4   120.3  91 4.43 2.140 16.70 0  1  5    2   \n",
       "Lotus Europa        30.4 4    95.1 113 3.77 1.513 16.90 1  1  5    2   \n",
       "Ford Pantera L      15.8 8   351.0 264 4.22 3.170 14.50 0  1  5    4   \n",
       "Ferrari Dino        19.7 6   145.0 175 3.62 2.770 15.50 0  1  5    6   \n",
       "Maserati Bora       15.0 8   301.0 335 3.54 3.570 14.60 0  1  5    8   \n",
       "Volvo 142E          21.4 4   121.0 109 4.11 2.780 18.60 1  1  4    2   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<table width=\"100%\" summary=\"page for mtcars {datasets}\"><tr><td>mtcars {datasets}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2>Motor Trend Car Road Tests</h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "<p>The data was extracted from the 1974 <em>Motor Trend</em> US magazine,\n",
       "and comprises fuel consumption and 10 aspects of\n",
       "automobile design and performance for 32 automobiles (1973&ndash;74\n",
       "models).\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Usage</h3>\n",
       "\n",
       "<pre>mtcars</pre>\n",
       "\n",
       "\n",
       "<h3>Format</h3>\n",
       "\n",
       "<p>A data frame with 32 observations on 11 (numeric) variables.\n",
       "</p>\n",
       "\n",
       "<table summary=\"Rd table\">\n",
       "<tr>\n",
       " <td style=\"text-align: right;\">\n",
       "    [, 1] </td><td style=\"text-align: left;\"> mpg  </td><td style=\"text-align: left;\"> Miles/(US) gallon </td>\n",
       "</tr>\n",
       "<tr>\n",
       " <td style=\"text-align: right;\">\n",
       "    [, 2] </td><td style=\"text-align: left;\"> cyl  </td><td style=\"text-align: left;\"> Number of cylinders </td>\n",
       "</tr>\n",
       "<tr>\n",
       " <td style=\"text-align: right;\">\n",
       "    [, 3] </td><td style=\"text-align: left;\"> disp </td><td style=\"text-align: left;\"> Displacement (cu.in.) </td>\n",
       "</tr>\n",
       "<tr>\n",
       " <td style=\"text-align: right;\">\n",
       "    [, 4] </td><td style=\"text-align: left;\"> hp   </td><td style=\"text-align: left;\"> Gross horsepower </td>\n",
       "</tr>\n",
       "<tr>\n",
       " <td style=\"text-align: right;\">\n",
       "    [, 5] </td><td style=\"text-align: left;\"> drat </td><td style=\"text-align: left;\"> Rear axle ratio </td>\n",
       "</tr>\n",
       "<tr>\n",
       " <td style=\"text-align: right;\">\n",
       "    [, 6] </td><td style=\"text-align: left;\"> wt   </td><td style=\"text-align: left;\"> Weight (1000 lbs) </td>\n",
       "</tr>\n",
       "<tr>\n",
       " <td style=\"text-align: right;\">\n",
       "    [, 7] </td><td style=\"text-align: left;\"> qsec </td><td style=\"text-align: left;\"> 1/4 mile time </td>\n",
       "</tr>\n",
       "<tr>\n",
       " <td style=\"text-align: right;\">\n",
       "    [, 8] </td><td style=\"text-align: left;\"> vs   </td><td style=\"text-align: left;\"> Engine (0 = V-shaped, 1 = straight) </td>\n",
       "</tr>\n",
       "<tr>\n",
       " <td style=\"text-align: right;\">\n",
       "    [, 9] </td><td style=\"text-align: left;\"> am   </td><td style=\"text-align: left;\"> Transmission (0 = automatic, 1 = manual) </td>\n",
       "</tr>\n",
       "<tr>\n",
       " <td style=\"text-align: right;\">\n",
       "    [,10] </td><td style=\"text-align: left;\"> gear </td><td style=\"text-align: left;\"> Number of forward gears </td>\n",
       "</tr>\n",
       "<tr>\n",
       " <td style=\"text-align: right;\">\n",
       "    [,11] </td><td style=\"text-align: left;\"> carb </td><td style=\"text-align: left;\"> Number of carburetors\n",
       "  </td>\n",
       "</tr>\n",
       "\n",
       "</table>\n",
       "\n",
       "\n",
       "\n",
       "<h3>Source</h3>\n",
       "\n",
       "<p>Henderson and Velleman (1981),\n",
       "Building multiple regression models interactively.\n",
       "<em>Biometrics</em>, <b>37</b>, 391&ndash;411.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Examples</h3>\n",
       "\n",
       "<pre>\n",
       "require(graphics)\n",
       "pairs(mtcars, main = \"mtcars data\", gap = 1/4)\n",
       "coplot(mpg ~ disp | as.factor(cyl), data = mtcars,\n",
       "       panel = panel.smooth, rows = 1)\n",
       "## possibly more meaningful, e.g., for summary() or bivariate plots:\n",
       "mtcars2 &lt;- within(mtcars, {\n",
       "   vs &lt;- factor(vs, labels = c(\"V\", \"S\"))\n",
       "   am &lt;- factor(am, labels = c(\"automatic\", \"manual\"))\n",
       "   cyl  &lt;- ordered(cyl)\n",
       "   gear &lt;- ordered(gear)\n",
       "   carb &lt;- ordered(carb)\n",
       "})\n",
       "summary(mtcars2)\n",
       "</pre>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>datasets</em> version 3.5.1 ]</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{mtcars}{Motor Trend Car Road Tests}{mtcars}\n",
       "\\keyword{datasets}{mtcars}\n",
       "%\n",
       "\\begin{Description}\\relax\n",
       "The data was extracted from the 1974 \\emph{Motor Trend} US magazine,\n",
       "and comprises fuel consumption and 10 aspects of\n",
       "automobile design and performance for 32 automobiles (1973--74\n",
       "models).\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "mtcars\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Format}\n",
       "A data frame with 32 observations on 11 (numeric) variables.\n",
       "\n",
       "\\Tabular{rll}{\n",
       "[, 1] & mpg  & Miles/(US) gallon \\\\{}\n",
       "[, 2] & cyl  & Number of cylinders \\\\{}\n",
       "[, 3] & disp & Displacement (cu.in.) \\\\{}\n",
       "[, 4] & hp   & Gross horsepower \\\\{}\n",
       "[, 5] & drat & Rear axle ratio \\\\{}\n",
       "[, 6] & wt   & Weight (1000 lbs) \\\\{}\n",
       "[, 7] & qsec & 1/4 mile time \\\\{}\n",
       "[, 8] & vs   & Engine (0 = V-shaped, 1 = straight) \\\\{}\n",
       "[, 9] & am   & Transmission (0 = automatic, 1 = manual) \\\\{}\n",
       "[,10] & gear & Number of forward gears \\\\{}\n",
       "[,11] & carb & Number of carburetors\n",
       "}\n",
       "\\end{Format}\n",
       "%\n",
       "\\begin{Source}\\relax\n",
       "Henderson and Velleman (1981),\n",
       "Building multiple regression models interactively.\n",
       "\\emph{Biometrics}, \\bold{37}, 391--411.\n",
       "\\end{Source}\n",
       "%\n",
       "\\begin{Examples}\n",
       "\\begin{ExampleCode}\n",
       "require(graphics)\n",
       "pairs(mtcars, main = \"mtcars data\", gap = 1/4)\n",
       "coplot(mpg ~ disp | as.factor(cyl), data = mtcars,\n",
       "       panel = panel.smooth, rows = 1)\n",
       "## possibly more meaningful, e.g., for summary() or bivariate plots:\n",
       "mtcars2 <- within(mtcars, {\n",
       "   vs <- factor(vs, labels = c(\"V\", \"S\"))\n",
       "   am <- factor(am, labels = c(\"automatic\", \"manual\"))\n",
       "   cyl  <- ordered(cyl)\n",
       "   gear <- ordered(gear)\n",
       "   carb <- ordered(carb)\n",
       "})\n",
       "summary(mtcars2)\n",
       "\\end{ExampleCode}\n",
       "\\end{Examples}"
      ],
      "text/plain": [
       "mtcars                package:datasets                 R Documentation\n",
       "\n",
       "_\bM_\bo_\bt_\bo_\br _\bT_\br_\be_\bn_\bd _\bC_\ba_\br _\bR_\bo_\ba_\bd _\bT_\be_\bs_\bt_\bs\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     The data was extracted from the 1974 _Motor Trend_ US magazine,\n",
       "     and comprises fuel consumption and 10 aspects of automobile design\n",
       "     and performance for 32 automobiles (1973-74 models).\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "     mtcars\n",
       "     \n",
       "_\bF_\bo_\br_\bm_\ba_\bt:\n",
       "\n",
       "     A data frame with 32 observations on 11 (numeric) variables.\n",
       "\n",
       "       [, 1]  mpg   Miles/(US) gallon                        \n",
       "       [, 2]  cyl   Number of cylinders                      \n",
       "       [, 3]  disp  Displacement (cu.in.)                    \n",
       "       [, 4]  hp    Gross horsepower                         \n",
       "       [, 5]  drat  Rear axle ratio                          \n",
       "       [, 6]  wt    Weight (1000 lbs)                        \n",
       "       [, 7]  qsec  1/4 mile time                            \n",
       "       [, 8]  vs    Engine (0 = V-shaped, 1 = straight)      \n",
       "       [, 9]  am    Transmission (0 = automatic, 1 = manual) \n",
       "       [,10]  gear  Number of forward gears                  \n",
       "       [,11]  carb  Number of carburetors                    \n",
       "      \n",
       "_\bS_\bo_\bu_\br_\bc_\be:\n",
       "\n",
       "     Henderson and Velleman (1981), Building multiple regression models\n",
       "     interactively.  _Biometrics_, *37*, 391-411.\n",
       "\n",
       "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
       "\n",
       "     require(graphics)\n",
       "     pairs(mtcars, main = \"mtcars data\", gap = 1/4)\n",
       "     coplot(mpg ~ disp | as.factor(cyl), data = mtcars,\n",
       "            panel = panel.smooth, rows = 1)\n",
       "     ## possibly more meaningful, e.g., for summary() or bivariate plots:\n",
       "     mtcars2 <- within(mtcars, {\n",
       "        vs <- factor(vs, labels = c(\"V\", \"S\"))\n",
       "        am <- factor(am, labels = c(\"automatic\", \"manual\"))\n",
       "        cyl  <- ordered(cyl)\n",
       "        gear <- ordered(gear)\n",
       "        carb <- ordered(carb)\n",
       "     })\n",
       "     summary(mtcars2)\n",
       "     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?mtcars\n",
    "mtcars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table width=\"100%\" summary=\"page for read.table {utils}\"><tr><td>read.table {utils}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2>Data Input</h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "<p>Reads a file in table format and creates a data frame from it, with\n",
       "cases corresponding to lines and variables to fields in the file.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Usage</h3>\n",
       "\n",
       "<pre>\n",
       "read.table(file, header = FALSE, sep = \"\", quote = \"\\\"'\",\n",
       "           dec = \".\", numerals = c(\"allow.loss\", \"warn.loss\", \"no.loss\"),\n",
       "           row.names, col.names, as.is = !stringsAsFactors,\n",
       "           na.strings = \"NA\", colClasses = NA, nrows = -1,\n",
       "           skip = 0, check.names = TRUE, fill = !blank.lines.skip,\n",
       "           strip.white = FALSE, blank.lines.skip = TRUE,\n",
       "           comment.char = \"#\",\n",
       "           allowEscapes = FALSE, flush = FALSE,\n",
       "           stringsAsFactors = default.stringsAsFactors(),\n",
       "           fileEncoding = \"\", encoding = \"unknown\", text, skipNul = FALSE)\n",
       "\n",
       "read.csv(file, header = TRUE, sep = \",\", quote = \"\\\"\",\n",
       "         dec = \".\", fill = TRUE, comment.char = \"\", ...)\n",
       "\n",
       "read.csv2(file, header = TRUE, sep = \";\", quote = \"\\\"\",\n",
       "          dec = \",\", fill = TRUE, comment.char = \"\", ...)\n",
       "\n",
       "read.delim(file, header = TRUE, sep = \"\\t\", quote = \"\\\"\",\n",
       "           dec = \".\", fill = TRUE, comment.char = \"\", ...)\n",
       "\n",
       "read.delim2(file, header = TRUE, sep = \"\\t\", quote = \"\\\"\",\n",
       "            dec = \",\", fill = TRUE, comment.char = \"\", ...)\n",
       "</pre>\n",
       "\n",
       "\n",
       "<h3>Arguments</h3>\n",
       "\n",
       "<table summary=\"R argblock\">\n",
       "<tr valign=\"top\"><td><code>file</code></td>\n",
       "<td>\n",
       "<p>the name of the file which the data are to be read from.\n",
       "Each row of the table appears as one line of the file.  If it does\n",
       "not contain an <em>absolute</em> path, the file name is\n",
       "<em>relative</em> to the current working directory,\n",
       "<code>getwd()</code>. Tilde-expansion is performed where supported.\n",
       "This can be a compressed file (see <code>file</code>).\n",
       "</p>\n",
       "<p>Alternatively, <code>file</code> can be a readable text-mode\n",
       "connection (which will be opened for reading if\n",
       "necessary, and if so <code>close</code>d (and hence destroyed) at\n",
       "the end of the function call).  (If <code>stdin()</code> is used,\n",
       "the prompts for lines may be somewhat confusing.  Terminate input\n",
       "with a blank line or an EOF signal, <code>Ctrl-D</code> on Unix and\n",
       "<code>Ctrl-Z</code> on Windows.  Any pushback on <code>stdin()</code> will be\n",
       "cleared before return.)\n",
       "</p>\n",
       "<p><code>file</code> can also be a complete URL.  (For the supported URL\n",
       "schemes, see the &lsquo;URLs&rsquo; section of the help for\n",
       "<code>url</code>.)\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>header</code></td>\n",
       "<td>\n",
       "<p>a logical value indicating whether the file contains the\n",
       "names of the variables as its first line.  If missing, the value is\n",
       "determined from the file format: <code>header</code> is set to <code>TRUE</code>\n",
       "if and only if the first row contains one fewer field than the\n",
       "number of columns.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>sep</code></td>\n",
       "<td>\n",
       "<p>the field separator character.  Values on each line of the\n",
       "file are separated by this character.  If <code>sep = \"\"</code> (the\n",
       "default for <code>read.table</code>) the separator is &lsquo;white space&rsquo;,\n",
       "that is one or more spaces, tabs, newlines or carriage returns.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>quote</code></td>\n",
       "<td>\n",
       "<p>the set of quoting characters. To disable quoting\n",
       "altogether, use <code>quote = \"\"</code>.  See <code>scan</code> for the\n",
       "behaviour on quotes embedded in quotes.  Quoting is only considered\n",
       "for columns read as character, which is all of them unless\n",
       "<code>colClasses</code> is specified.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>dec</code></td>\n",
       "<td>\n",
       "<p>the character used in the file for decimal points.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>numerals</code></td>\n",
       "<td>\n",
       "<p>string indicating how to convert numbers whose conversion\n",
       "to double precision would lose accuracy, see <code>type.convert</code>.\n",
       "Can be abbreviated.  (Applies also to complex-number inputs.)</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>row.names</code></td>\n",
       "<td>\n",
       "<p>a vector of row names.  This can be a vector giving\n",
       "the actual row names, or a single number giving the column of the\n",
       "table which contains the row names, or character string giving the\n",
       "name of the table column containing the row names.\n",
       "</p>\n",
       "<p>If there is a header and the first row contains one fewer field than\n",
       "the number of columns, the first column in the input is used for the\n",
       "row names.  Otherwise if <code>row.names</code> is missing, the rows are\n",
       "numbered.\n",
       "</p>\n",
       "<p>Using <code>row.names = NULL</code> forces row numbering. Missing or\n",
       "<code>NULL</code> <code>row.names</code> generate row names that are considered\n",
       "to be &lsquo;automatic&rsquo; (and not preserved by <code>as.matrix</code>).\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>col.names</code></td>\n",
       "<td>\n",
       "<p>a vector of optional names for the variables.\n",
       "The default is to use <code>\"V\"</code> followed by the column number.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>as.is</code></td>\n",
       "<td>\n",
       "<p>the default behavior of <code>read.table</code> is to convert\n",
       "character variables (which are not converted to logical, numeric or\n",
       "complex) to factors.  The variable <code>as.is</code> controls the\n",
       "conversion of columns not otherwise specified by <code>colClasses</code>.\n",
       "Its value is either a vector of logicals (values are recycled if\n",
       "necessary), or a vector of numeric or character indices which\n",
       "specify which columns should not be converted to factors.\n",
       "</p>\n",
       "<p>Note: to suppress all conversions including those of numeric\n",
       "columns, set <code>colClasses = \"character\"</code>.\n",
       "</p>\n",
       "<p>Note that <code>as.is</code> is specified per column (not per\n",
       "variable) and so includes the column of row names (if any) and any\n",
       "columns to be skipped.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>na.strings</code></td>\n",
       "<td>\n",
       "<p>a character vector of strings which are to be\n",
       "interpreted as <code>NA</code> values.  Blank fields are also\n",
       "considered to be missing values in logical, integer, numeric and\n",
       "complex fields.  Note that the test happens <em>after</em> \n",
       "white space is stripped from the input, so <code>na.strings</code> \n",
       "values may need their own white space stripped in advance.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>colClasses</code></td>\n",
       "<td>\n",
       "<p>character.  A vector of classes to be assumed for\n",
       "the columns.  If unnamed, recycled as necessary.  If named, names\n",
       "are matched with unspecified values being taken to be <code>NA</code>.\n",
       "</p>\n",
       "<p>Possible values are <code>NA</code> (the default, when\n",
       "<code>type.convert</code> is used), <code>\"NULL\"</code> (when the column\n",
       "is skipped), one of the atomic vector classes (logical, integer,\n",
       "numeric, complex, character, raw), or <code>\"factor\"</code>, <code>\"Date\"</code>\n",
       "or <code>\"POSIXct\"</code>.  Otherwise there needs to be an <code>as</code>\n",
       "method (from package <span class=\"pkg\">methods</span>) for conversion from\n",
       "<code>\"character\"</code> to the specified formal class.\n",
       "</p>\n",
       "<p>Note that <code>colClasses</code> is specified per column (not per\n",
       "variable) and so includes the column of row names (if any).\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>nrows</code></td>\n",
       "<td>\n",
       "<p>integer: the maximum number of rows to read in.  Negative\n",
       "and other invalid values are ignored.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>skip</code></td>\n",
       "<td>\n",
       "<p>integer: the number of lines of the data file to skip before\n",
       "beginning to read data.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>check.names</code></td>\n",
       "<td>\n",
       "<p>logical.  If <code>TRUE</code> then the names of the\n",
       "variables in the data frame are checked to ensure that they are\n",
       "syntactically valid variable names.  If necessary they are adjusted\n",
       "(by <code>make.names</code>) so that they are, and also to ensure\n",
       "that there are no duplicates.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>fill</code></td>\n",
       "<td>\n",
       "<p>logical. If <code>TRUE</code> then in case the rows have unequal\n",
       "length, blank fields are implicitly added.  See &lsquo;Details&rsquo;.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>strip.white</code></td>\n",
       "<td>\n",
       "<p>logical. Used only when <code>sep</code> has\n",
       "been specified, and allows the stripping of leading and trailing\n",
       "white space from unquoted <code>character</code> fields (<code>numeric</code> fields\n",
       "are always stripped).  See <code>scan</code> for further details\n",
       "(including the exact meaning of &lsquo;white space&rsquo;),\n",
       "remembering that the columns may include the row names.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>blank.lines.skip</code></td>\n",
       "<td>\n",
       "<p>logical: if <code>TRUE</code> blank lines in the\n",
       "input are ignored.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>comment.char</code></td>\n",
       "<td>\n",
       "<p>character: a character vector of length one\n",
       "containing a single character or an empty string.  Use <code>\"\"</code> to\n",
       "turn off the interpretation of comments altogether.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>allowEscapes</code></td>\n",
       "<td>\n",
       "<p>logical.  Should C-style escapes such as\n",
       "<span class=\"samp\">\\n</span> be processed or read verbatim (the default)?   Note that if\n",
       "not within quotes these could be interpreted as a delimiter (but not\n",
       "as a comment character).  For more details see <code>scan</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>flush</code></td>\n",
       "<td>\n",
       "<p>logical: if <code>TRUE</code>, <code>scan</code> will flush to the\n",
       "end of the line after reading the last of the fields requested.\n",
       "This allows putting comments after the last field.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>stringsAsFactors</code></td>\n",
       "<td>\n",
       "<p>logical: should character vectors be converted\n",
       "to factors?  Note that this is overridden by <code>as.is</code> and\n",
       "<code>colClasses</code>, both of which allow finer control.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>fileEncoding</code></td>\n",
       "<td>\n",
       "<p>character string: if non-empty declares the\n",
       "encoding used on a file (not a connection) so the character data can\n",
       "be re-encoded.  See the &lsquo;Encoding&rsquo; section of the help for\n",
       "<code>file</code>, the &lsquo;R Data Import/Export Manual&rsquo; and\n",
       "&lsquo;Note&rsquo;.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>encoding</code></td>\n",
       "<td>\n",
       "<p>encoding to be assumed for input strings.  It is\n",
       "used to mark character strings as known to be in\n",
       "Latin-1 or UTF-8 (see <code>Encoding</code>): it is not used to\n",
       "re-encode the input, but allows <span style=\"font-family: Courier New, Courier; color: #666666;\"><b>R</b></span> to handle encoded strings in\n",
       "their native encoding (if one of those two).  See &lsquo;Value&rsquo;\n",
       "and &lsquo;Note&rsquo;.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>text</code></td>\n",
       "<td>\n",
       "<p>character string: if <code>file</code> is not supplied and this is,\n",
       "then data are read from the value of <code>text</code> via a text connection.\n",
       "Notice that a literal string can be used to include (small) data sets\n",
       "within R code.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>skipNul</code></td>\n",
       "<td>\n",
       "<p>logical: should nuls be skipped?</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>...</code></td>\n",
       "<td>\n",
       "<p>Further arguments to be passed to <code>read.table</code>.</p>\n",
       "</td></tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "<h3>Details</h3>\n",
       "\n",
       "<p>This function is the principal means of reading tabular data into <span style=\"font-family: Courier New, Courier; color: #666666;\"><b>R</b></span>.\n",
       "</p>\n",
       "<p>Unless <code>colClasses</code> is specified, all columns are read as\n",
       "character columns and then converted using <code>type.convert</code>\n",
       "to logical, integer, numeric, complex or (depending on <code>as.is</code>)\n",
       "factor as appropriate.  Quotes are (by default) interpreted in all\n",
       "fields, so a column of values like <code>\"42\"</code> will result in an\n",
       "integer column.\n",
       "</p>\n",
       "<p>A field or line is &lsquo;blank&rsquo; if it contains nothing (except\n",
       "whitespace if no separator is specified) before a comment character or\n",
       "the end of the field or line.\n",
       "</p>\n",
       "<p>If <code>row.names</code> is not specified and the header line has one less\n",
       "entry than the number of columns, the first column is taken to be the\n",
       "row names.  This allows data frames to be read in from the format in\n",
       "which they are printed.  If <code>row.names</code> is specified and does\n",
       "not refer to the first column, that column is discarded from such files.\n",
       "</p>\n",
       "<p>The number of data columns is determined by looking at the first five\n",
       "lines of input (or the whole input if it has less than five lines), or\n",
       "from the length of <code>col.names</code> if it is specified and is longer.\n",
       "This could conceivably be wrong if <code>fill</code> or\n",
       "<code>blank.lines.skip</code> are true, so specify <code>col.names</code> if\n",
       "necessary (as in the &lsquo;Examples&rsquo;).\n",
       "</p>\n",
       "<p><code>read.csv</code> and <code>read.csv2</code> are identical to\n",
       "<code>read.table</code> except for the defaults.  They are intended for\n",
       "reading &lsquo;comma separated value&rsquo; files (&lsquo;<span class=\"file\">.csv</span>&rsquo;) or\n",
       "(<code>read.csv2</code>) the variant used in countries that use a comma as\n",
       "decimal point and a semicolon as field separator.  Similarly,\n",
       "<code>read.delim</code> and <code>read.delim2</code> are for reading delimited\n",
       "files, defaulting to the TAB character for the delimiter.  Notice that\n",
       "<code>header = TRUE</code> and <code>fill = TRUE</code> in these variants, and\n",
       "that the comment character is disabled.\n",
       "</p>\n",
       "<p>The rest of the line after a comment character is skipped; quotes\n",
       "are not processed in comments.  Complete comment lines are allowed\n",
       "provided <code>blank.lines.skip = TRUE</code>; however, comment lines prior\n",
       "to the header must have the comment character in the first non-blank\n",
       "column.\n",
       "</p>\n",
       "<p>Quoted fields with embedded newlines are supported except after a\n",
       "comment character.  Embedded nuls are unsupported: skipping them (with\n",
       "<code>skipNul = TRUE</code>) may work.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Value</h3>\n",
       "\n",
       "<p>A data frame (<code>data.frame</code>) containing a representation of\n",
       "the data in the file.\n",
       "</p>\n",
       "<p>Empty input is an error unless <code>col.names</code> is specified, when a\n",
       "0-row data frame is returned: similarly giving just a header line if\n",
       "<code>header = TRUE</code> results in a 0-row data frame.  Note that in\n",
       "either case the columns will be logical unless <code>colClasses</code> was\n",
       "supplied.\n",
       "</p>\n",
       "<p>Character strings in the result (including factor levels) will have a\n",
       "declared encoding if <code>encoding</code> is <code>\"latin1\"</code> or\n",
       "<code>\"UTF-8\"</code>.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Memory usage</h3>\n",
       "\n",
       "<p>These functions can use a surprising amount of memory when reading\n",
       "large files.  There is extensive discussion in the &lsquo;R Data\n",
       "Import/Export&rsquo; manual, supplementing the notes here.\n",
       "</p>\n",
       "<p>Less memory will be used if <code>colClasses</code> is specified as one of\n",
       "the six atomic vector classes.  This can be particularly so when\n",
       "reading a column that takes many distinct numeric values, as storing\n",
       "each distinct value as a character string can take up to 14 times as\n",
       "much memory as storing it as an integer.\n",
       "</p>\n",
       "<p>Using <code>nrows</code>, even as a mild over-estimate, will help memory\n",
       "usage.\n",
       "</p>\n",
       "<p>Using <code>comment.char = \"\"</code> will be appreciably faster than the\n",
       "<code>read.table</code> default.\n",
       "</p>\n",
       "<p><code>read.table</code> is not the right tool for reading large matrices,\n",
       "especially those with many columns: it is designed to read\n",
       "<em>data frames</em> which may have columns of very different classes.\n",
       "Use <code>scan</code> instead for matrices.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Note</h3>\n",
       "\n",
       "<p>The columns referred to in <code>as.is</code> and <code>colClasses</code> include\n",
       "the column of row names (if any).\n",
       "</p>\n",
       "<p>There are two approaches for reading input that is not in the local\n",
       "encoding.  If the input is known to be UTF-8 or Latin1, use the\n",
       "<code>encoding</code> argument to declare that.  If the input is in some\n",
       "other encoding, then it may be translated on input.  The <code>fileEncoding</code>\n",
       "argument achieves this by setting up a connection to do the re-encoding\n",
       "into the current locale.  Note that on Windows or other systems not running\n",
       "in a UTF-8 locale, this may not be possible.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>References</h3>\n",
       "\n",
       "<p>Chambers, J. M. (1992)\n",
       "<em>Data for models.</em>\n",
       "Chapter 3 of <em>Statistical Models in S</em>\n",
       "eds J. M. Chambers and T. J. Hastie, Wadsworth &amp; Brooks/Cole.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>See Also</h3>\n",
       "\n",
       "<p>The &lsquo;R Data Import/Export&rsquo; manual.\n",
       "</p>\n",
       "<p><code>scan</code>, <code>type.convert</code>,\n",
       "<code>read.fwf</code> for reading <em>f</em>ixed <em>w</em>idth\n",
       "<em>f</em>ormatted input;\n",
       "<code>write.table</code>;\n",
       "<code>data.frame</code>.\n",
       "</p>\n",
       "<p><code>count.fields</code> can be useful to determine problems with\n",
       "reading files which result in reports of incorrect record lengths (see\n",
       "the &lsquo;Examples&rsquo; below).\n",
       "</p>\n",
       "<p><a href=\"https://tools.ietf.org/html/rfc4180\">https://tools.ietf.org/html/rfc4180</a> for the IANA definition of\n",
       "CSV files (which requires comma as separator and CRLF line endings).\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Examples</h3>\n",
       "\n",
       "<pre>\n",
       "## using count.fields to handle unknown maximum number of fields\n",
       "## when fill = TRUE\n",
       "test1 &lt;- c(1:5, \"6,7\", \"8,9,10\")\n",
       "tf &lt;- tempfile()\n",
       "writeLines(test1, tf)\n",
       "\n",
       "read.csv(tf, fill = TRUE) # 1 column\n",
       "ncol &lt;- max(count.fields(tf, sep = \",\"))\n",
       "read.csv(tf, fill = TRUE, header = FALSE,\n",
       "         col.names = paste0(\"V\", seq_len(ncol)))\n",
       "unlink(tf)\n",
       "\n",
       "## \"Inline\" data set, using text=\n",
       "## Notice that leading and trailing empty lines are auto-trimmed\n",
       "\n",
       "read.table(header = TRUE, text = \"\n",
       "a b\n",
       "1 2\n",
       "3 4\n",
       "\")\n",
       "</pre>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>utils</em> version 3.5.1 ]</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{read.table}{Data Input}{read.table}\n",
       "\\aliasA{read.csv}{read.table}{read.csv}\n",
       "\\aliasA{read.csv2}{read.table}{read.csv2}\n",
       "\\aliasA{read.delim}{read.table}{read.delim}\n",
       "\\aliasA{read.delim2}{read.table}{read.delim2}\n",
       "\\keyword{file}{read.table}\n",
       "\\keyword{connection}{read.table}\n",
       "%\n",
       "\\begin{Description}\\relax\n",
       "Reads a file in table format and creates a data frame from it, with\n",
       "cases corresponding to lines and variables to fields in the file.\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "read.table(file, header = FALSE, sep = \"\", quote = \"\\\"'\",\n",
       "           dec = \".\", numerals = c(\"allow.loss\", \"warn.loss\", \"no.loss\"),\n",
       "           row.names, col.names, as.is = !stringsAsFactors,\n",
       "           na.strings = \"NA\", colClasses = NA, nrows = -1,\n",
       "           skip = 0, check.names = TRUE, fill = !blank.lines.skip,\n",
       "           strip.white = FALSE, blank.lines.skip = TRUE,\n",
       "           comment.char = \"#\",\n",
       "           allowEscapes = FALSE, flush = FALSE,\n",
       "           stringsAsFactors = default.stringsAsFactors(),\n",
       "           fileEncoding = \"\", encoding = \"unknown\", text, skipNul = FALSE)\n",
       "\n",
       "read.csv(file, header = TRUE, sep = \",\", quote = \"\\\"\",\n",
       "         dec = \".\", fill = TRUE, comment.char = \"\", ...)\n",
       "\n",
       "read.csv2(file, header = TRUE, sep = \";\", quote = \"\\\"\",\n",
       "          dec = \",\", fill = TRUE, comment.char = \"\", ...)\n",
       "\n",
       "read.delim(file, header = TRUE, sep = \"\\t\", quote = \"\\\"\",\n",
       "           dec = \".\", fill = TRUE, comment.char = \"\", ...)\n",
       "\n",
       "read.delim2(file, header = TRUE, sep = \"\\t\", quote = \"\\\"\",\n",
       "            dec = \",\", fill = TRUE, comment.char = \"\", ...)\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Arguments}\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{file}] the name of the file which the data are to be read from.\n",
       "Each row of the table appears as one line of the file.  If it does\n",
       "not contain an \\emph{absolute} path, the file name is\n",
       "\\emph{relative} to the current working directory,\n",
       "\\code{\\LinkA{getwd}{getwd}()}. Tilde-expansion is performed where supported.\n",
       "This can be a compressed file (see \\code{\\LinkA{file}{file}}).\n",
       "\n",
       "Alternatively, \\code{file} can be a readable text-mode\n",
       "\\LinkA{connection}{connection} (which will be opened for reading if\n",
       "necessary, and if so \\code{\\LinkA{close}{close}}d (and hence destroyed) at\n",
       "the end of the function call).  (If \\code{\\LinkA{stdin}{stdin}()} is used,\n",
       "the prompts for lines may be somewhat confusing.  Terminate input\n",
       "with a blank line or an EOF signal, \\code{Ctrl-D} on Unix and\n",
       "\\code{Ctrl-Z} on Windows.  Any pushback on \\code{stdin()} will be\n",
       "cleared before return.)\n",
       "\n",
       "\\code{file} can also be a complete URL.  (For the supported URL\n",
       "schemes, see the `URLs' section of the help for\n",
       "\\code{\\LinkA{url}{url}}.)\n",
       "\n",
       "\n",
       "\\item[\\code{header}] a logical value indicating whether the file contains the\n",
       "names of the variables as its first line.  If missing, the value is\n",
       "determined from the file format: \\code{header} is set to \\code{TRUE}\n",
       "if and only if the first row contains one fewer field than the\n",
       "number of columns.\n",
       "\n",
       "\\item[\\code{sep}] the field separator character.  Values on each line of the\n",
       "file are separated by this character.  If \\code{sep = \"\"} (the\n",
       "default for \\code{read.table}) the separator is `white space',\n",
       "that is one or more spaces, tabs, newlines or carriage returns.\n",
       "\n",
       "\\item[\\code{quote}] the set of quoting characters. To disable quoting\n",
       "altogether, use \\code{quote = \"\"}.  See \\code{\\LinkA{scan}{scan}} for the\n",
       "behaviour on quotes embedded in quotes.  Quoting is only considered\n",
       "for columns read as character, which is all of them unless\n",
       "\\code{colClasses} is specified.\n",
       "\n",
       "\\item[\\code{dec}] the character used in the file for decimal points.\n",
       "\n",
       "\\item[\\code{numerals}] string indicating how to convert numbers whose conversion\n",
       "to double precision would lose accuracy, see \\code{\\LinkA{type.convert}{type.convert}}.\n",
       "Can be abbreviated.  (Applies also to complex-number inputs.)\n",
       "\n",
       "\\item[\\code{row.names}] a vector of row names.  This can be a vector giving\n",
       "the actual row names, or a single number giving the column of the\n",
       "table which contains the row names, or character string giving the\n",
       "name of the table column containing the row names.\n",
       "\n",
       "If there is a header and the first row contains one fewer field than\n",
       "the number of columns, the first column in the input is used for the\n",
       "row names.  Otherwise if \\code{row.names} is missing, the rows are\n",
       "numbered.\n",
       "\n",
       "Using \\code{row.names = NULL} forces row numbering. Missing or\n",
       "\\code{NULL} \\code{row.names} generate row names that are considered\n",
       "to be `automatic' (and not preserved by \\code{\\LinkA{as.matrix}{as.matrix}}).\n",
       "\n",
       "\n",
       "\\item[\\code{col.names}] a vector of optional names for the variables.\n",
       "The default is to use \\code{\"V\"} followed by the column number.\n",
       "\n",
       "\\item[\\code{as.is}] the default behavior of \\code{read.table} is to convert\n",
       "character variables (which are not converted to logical, numeric or\n",
       "complex) to factors.  The variable \\code{as.is} controls the\n",
       "conversion of columns not otherwise specified by \\code{colClasses}.\n",
       "Its value is either a vector of logicals (values are recycled if\n",
       "necessary), or a vector of numeric or character indices which\n",
       "specify which columns should not be converted to factors.\n",
       "\n",
       "Note: to suppress all conversions including those of numeric\n",
       "columns, set \\code{colClasses = \"character\"}.\n",
       "\n",
       "Note that \\code{as.is} is specified per column (not per\n",
       "variable) and so includes the column of row names (if any) and any\n",
       "columns to be skipped.\n",
       "\n",
       "\n",
       "\\item[\\code{na.strings}] a character vector of strings which are to be\n",
       "interpreted as \\code{\\LinkA{NA}{NA}} values.  Blank fields are also\n",
       "considered to be missing values in logical, integer, numeric and\n",
       "complex fields.  Note that the test happens \\emph{after} \n",
       "white space is stripped from the input, so \\code{na.strings} \n",
       "values may need their own white space stripped in advance.\n",
       "\n",
       "\\item[\\code{colClasses}] character.  A vector of classes to be assumed for\n",
       "the columns.  If unnamed, recycled as necessary.  If named, names\n",
       "are matched with unspecified values being taken to be \\code{NA}.\n",
       "\n",
       "Possible values are \\code{NA} (the default, when\n",
       "\\code{\\LinkA{type.convert}{type.convert}} is used), \\code{\"NULL\"} (when the column\n",
       "is skipped), one of the atomic vector classes (logical, integer,\n",
       "numeric, complex, character, raw), or \\code{\"factor\"}, \\code{\"Date\"}\n",
       "or \\code{\"POSIXct\"}.  Otherwise there needs to be an \\code{as}\n",
       "method (from package \\pkg{methods}) for conversion from\n",
       "\\code{\"character\"} to the specified formal class.\n",
       "\n",
       "Note that \\code{colClasses} is specified per column (not per\n",
       "variable) and so includes the column of row names (if any).\n",
       "\n",
       "\n",
       "\\item[\\code{nrows}] integer: the maximum number of rows to read in.  Negative\n",
       "and other invalid values are ignored.\n",
       "\n",
       "\\item[\\code{skip}] integer: the number of lines of the data file to skip before\n",
       "beginning to read data.\n",
       "\n",
       "\\item[\\code{check.names}] logical.  If \\code{TRUE} then the names of the\n",
       "variables in the data frame are checked to ensure that they are\n",
       "syntactically valid variable names.  If necessary they are adjusted\n",
       "(by \\code{\\LinkA{make.names}{make.names}}) so that they are, and also to ensure\n",
       "that there are no duplicates.\n",
       "\n",
       "\\item[\\code{fill}] logical. If \\code{TRUE} then in case the rows have unequal\n",
       "length, blank fields are implicitly added.  See `Details'.\n",
       "\n",
       "\\item[\\code{strip.white}] logical. Used only when \\code{sep} has\n",
       "been specified, and allows the stripping of leading and trailing\n",
       "white space from unquoted \\code{character} fields (\\code{numeric} fields\n",
       "are always stripped).  See \\code{\\LinkA{scan}{scan}} for further details\n",
       "(including the exact meaning of `white space'),\n",
       "remembering that the columns may include the row names.\n",
       "\n",
       "\\item[\\code{blank.lines.skip}] logical: if \\code{TRUE} blank lines in the\n",
       "input are ignored.\n",
       "\n",
       "\\item[\\code{comment.char}] character: a character vector of length one\n",
       "containing a single character or an empty string.  Use \\code{\"\"} to\n",
       "turn off the interpretation of comments altogether.\n",
       "\n",
       "\\item[\\code{allowEscapes}] logical.  Should C-style escapes such as\n",
       "\\samp{\\bsl{}n} be processed or read verbatim (the default)?   Note that if\n",
       "not within quotes these could be interpreted as a delimiter (but not\n",
       "as a comment character).  For more details see \\code{\\LinkA{scan}{scan}}.\n",
       "\n",
       "\\item[\\code{flush}] logical: if \\code{TRUE}, \\code{scan} will flush to the\n",
       "end of the line after reading the last of the fields requested.\n",
       "This allows putting comments after the last field.\n",
       "\n",
       "\\item[\\code{stringsAsFactors}] logical: should character vectors be converted\n",
       "to factors?  Note that this is overridden by \\code{as.is} and\n",
       "\\code{colClasses}, both of which allow finer control.\n",
       "\n",
       "\\item[\\code{fileEncoding}] character string: if non-empty declares the\n",
       "encoding used on a file (not a connection) so the character data can\n",
       "be re-encoded.  See the `Encoding' section of the help for\n",
       "\\code{\\LinkA{file}{file}}, the `R Data Import/Export Manual' and\n",
       "`Note'.\n",
       "\n",
       "\n",
       "\\item[\\code{encoding}] encoding to be assumed for input strings.  It is\n",
       "used to mark character strings as known to be in\n",
       "Latin-1 or UTF-8 (see \\code{\\LinkA{Encoding}{Encoding}}): it is not used to\n",
       "re-encode the input, but allows \\R{} to handle encoded strings in\n",
       "their native encoding (if one of those two).  See `Value'\n",
       "and `Note'.\n",
       "\n",
       "\n",
       "\\item[\\code{text}] character string: if \\code{file} is not supplied and this is,\n",
       "then data are read from the value of \\code{text} via a text connection.\n",
       "Notice that a literal string can be used to include (small) data sets\n",
       "within R code.\n",
       "\n",
       "\n",
       "\\item[\\code{skipNul}] logical: should nuls be skipped?\n",
       "\n",
       "\\item[\\code{...}] Further arguments to be passed to \\code{read.table}.\n",
       "\\end{ldescription}\n",
       "\\end{Arguments}\n",
       "%\n",
       "\\begin{Details}\\relax\n",
       "This function is the principal means of reading tabular data into \\R{}.\n",
       "\n",
       "Unless \\code{colClasses} is specified, all columns are read as\n",
       "character columns and then converted using \\code{\\LinkA{type.convert}{type.convert}}\n",
       "to logical, integer, numeric, complex or (depending on \\code{as.is})\n",
       "factor as appropriate.  Quotes are (by default) interpreted in all\n",
       "fields, so a column of values like \\code{\"42\"} will result in an\n",
       "integer column.\n",
       "\n",
       "A field or line is `blank' if it contains nothing (except\n",
       "whitespace if no separator is specified) before a comment character or\n",
       "the end of the field or line.\n",
       "\n",
       "If \\code{row.names} is not specified and the header line has one less\n",
       "entry than the number of columns, the first column is taken to be the\n",
       "row names.  This allows data frames to be read in from the format in\n",
       "which they are printed.  If \\code{row.names} is specified and does\n",
       "not refer to the first column, that column is discarded from such files.\n",
       "\n",
       "The number of data columns is determined by looking at the first five\n",
       "lines of input (or the whole input if it has less than five lines), or\n",
       "from the length of \\code{col.names} if it is specified and is longer.\n",
       "This could conceivably be wrong if \\code{fill} or\n",
       "\\code{blank.lines.skip} are true, so specify \\code{col.names} if\n",
       "necessary (as in the `Examples').\n",
       "\n",
       "\\code{read.csv} and \\code{read.csv2} are identical to\n",
       "\\code{read.table} except for the defaults.  They are intended for\n",
       "reading `comma separated value' files (\\file{.csv}) or\n",
       "(\\code{read.csv2}) the variant used in countries that use a comma as\n",
       "decimal point and a semicolon as field separator.  Similarly,\n",
       "\\code{read.delim} and \\code{read.delim2} are for reading delimited\n",
       "files, defaulting to the TAB character for the delimiter.  Notice that\n",
       "\\code{header = TRUE} and \\code{fill = TRUE} in these variants, and\n",
       "that the comment character is disabled.\n",
       "\n",
       "The rest of the line after a comment character is skipped; quotes\n",
       "are not processed in comments.  Complete comment lines are allowed\n",
       "provided \\code{blank.lines.skip = TRUE}; however, comment lines prior\n",
       "to the header must have the comment character in the first non-blank\n",
       "column.\n",
       "\n",
       "Quoted fields with embedded newlines are supported except after a\n",
       "comment character.  Embedded nuls are unsupported: skipping them (with\n",
       "\\code{skipNul = TRUE}) may work.\n",
       "\\end{Details}\n",
       "%\n",
       "\\begin{Value}\n",
       "A data frame (\\code{\\LinkA{data.frame}{data.frame}}) containing a representation of\n",
       "the data in the file.\n",
       "\n",
       "Empty input is an error unless \\code{col.names} is specified, when a\n",
       "0-row data frame is returned: similarly giving just a header line if\n",
       "\\code{header = TRUE} results in a 0-row data frame.  Note that in\n",
       "either case the columns will be logical unless \\code{colClasses} was\n",
       "supplied.\n",
       "\n",
       "Character strings in the result (including factor levels) will have a\n",
       "declared encoding if \\code{encoding} is \\code{\"latin1\"} or\n",
       "\\code{\"UTF-8\"}.\n",
       "\\end{Value}\n",
       "%\n",
       "\\begin{Section}{Memory usage}\n",
       "These functions can use a surprising amount of memory when reading\n",
       "large files.  There is extensive discussion in the `R Data\n",
       "Import/Export' manual, supplementing the notes here.\n",
       "\n",
       "Less memory will be used if \\code{colClasses} is specified as one of\n",
       "the six \\LinkA{atomic}{atomic} vector classes.  This can be particularly so when\n",
       "reading a column that takes many distinct numeric values, as storing\n",
       "each distinct value as a character string can take up to 14 times as\n",
       "much memory as storing it as an integer.\n",
       "\n",
       "Using \\code{nrows}, even as a mild over-estimate, will help memory\n",
       "usage.\n",
       "\n",
       "Using \\code{comment.char = \"\"} will be appreciably faster than the\n",
       "\\code{read.table} default.\n",
       "\n",
       "\\code{read.table} is not the right tool for reading large matrices,\n",
       "especially those with many columns: it is designed to read\n",
       "\\emph{data frames} which may have columns of very different classes.\n",
       "Use \\code{\\LinkA{scan}{scan}} instead for matrices.\n",
       "\\end{Section}\n",
       "%\n",
       "\\begin{Note}\\relax\n",
       "The columns referred to in \\code{as.is} and \\code{colClasses} include\n",
       "the column of row names (if any).\n",
       "\n",
       "There are two approaches for reading input that is not in the local\n",
       "encoding.  If the input is known to be UTF-8 or Latin1, use the\n",
       "\\code{encoding} argument to declare that.  If the input is in some\n",
       "other encoding, then it may be translated on input.  The \\code{fileEncoding}\n",
       "argument achieves this by setting up a connection to do the re-encoding\n",
       "into the current locale.  Note that on Windows or other systems not running\n",
       "in a UTF-8 locale, this may not be possible.\n",
       "\\end{Note}\n",
       "%\n",
       "\\begin{References}\\relax\n",
       "Chambers, J. M. (1992)\n",
       "\\emph{Data for models.}\n",
       "Chapter 3 of \\emph{Statistical Models in S}\n",
       "eds J. M. Chambers and T. J. Hastie, Wadsworth \\& Brooks/Cole.\n",
       "\\end{References}\n",
       "%\n",
       "\\begin{SeeAlso}\\relax\n",
       "The `R Data Import/Export' manual.\n",
       "\n",
       "\\code{\\LinkA{scan}{scan}}, \\code{\\LinkA{type.convert}{type.convert}},\n",
       "\\code{\\LinkA{read.fwf}{read.fwf}} for reading \\emph{f}ixed \\emph{w}idth\n",
       "\\emph{f}ormatted input;\n",
       "\\code{\\LinkA{write.table}{write.table}};\n",
       "\\code{\\LinkA{data.frame}{data.frame}}.\n",
       "\n",
       "\\code{\\LinkA{count.fields}{count.fields}} can be useful to determine problems with\n",
       "reading files which result in reports of incorrect record lengths (see\n",
       "the `Examples' below).\n",
       "\n",
       "\\url{https://tools.ietf.org/html/rfc4180} for the IANA definition of\n",
       "CSV files (which requires comma as separator and CRLF line endings).\n",
       "\\end{SeeAlso}\n",
       "%\n",
       "\\begin{Examples}\n",
       "\\begin{ExampleCode}\n",
       "## using count.fields to handle unknown maximum number of fields\n",
       "## when fill = TRUE\n",
       "test1 <- c(1:5, \"6,7\", \"8,9,10\")\n",
       "tf <- tempfile()\n",
       "writeLines(test1, tf)\n",
       "\n",
       "read.csv(tf, fill = TRUE) # 1 column\n",
       "ncol <- max(count.fields(tf, sep = \",\"))\n",
       "read.csv(tf, fill = TRUE, header = FALSE,\n",
       "         col.names = paste0(\"V\", seq_len(ncol)))\n",
       "unlink(tf)\n",
       "\n",
       "## \"Inline\" data set, using text=\n",
       "## Notice that leading and trailing empty lines are auto-trimmed\n",
       "\n",
       "read.table(header = TRUE, text = \"\n",
       "a b\n",
       "1 2\n",
       "3 4\n",
       "\")\n",
       "\\end{ExampleCode}\n",
       "\\end{Examples}"
      ],
      "text/plain": [
       "read.table                package:utils                R Documentation\n",
       "\n",
       "_\bD_\ba_\bt_\ba _\bI_\bn_\bp_\bu_\bt\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     Reads a file in table format and creates a data frame from it,\n",
       "     with cases corresponding to lines and variables to fields in the\n",
       "     file.\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "     read.table(file, header = FALSE, sep = \"\", quote = \"\\\"'\",\n",
       "                dec = \".\", numerals = c(\"allow.loss\", \"warn.loss\", \"no.loss\"),\n",
       "                row.names, col.names, as.is = !stringsAsFactors,\n",
       "                na.strings = \"NA\", colClasses = NA, nrows = -1,\n",
       "                skip = 0, check.names = TRUE, fill = !blank.lines.skip,\n",
       "                strip.white = FALSE, blank.lines.skip = TRUE,\n",
       "                comment.char = \"#\",\n",
       "                allowEscapes = FALSE, flush = FALSE,\n",
       "                stringsAsFactors = default.stringsAsFactors(),\n",
       "                fileEncoding = \"\", encoding = \"unknown\", text, skipNul = FALSE)\n",
       "     \n",
       "     read.csv(file, header = TRUE, sep = \",\", quote = \"\\\"\",\n",
       "              dec = \".\", fill = TRUE, comment.char = \"\", ...)\n",
       "     \n",
       "     read.csv2(file, header = TRUE, sep = \";\", quote = \"\\\"\",\n",
       "               dec = \",\", fill = TRUE, comment.char = \"\", ...)\n",
       "     \n",
       "     read.delim(file, header = TRUE, sep = \"\\t\", quote = \"\\\"\",\n",
       "                dec = \".\", fill = TRUE, comment.char = \"\", ...)\n",
       "     \n",
       "     read.delim2(file, header = TRUE, sep = \"\\t\", quote = \"\\\"\",\n",
       "                 dec = \",\", fill = TRUE, comment.char = \"\", ...)\n",
       "     \n",
       "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
       "\n",
       "    file: the name of the file which the data are to be read from.\n",
       "          Each row of the table appears as one line of the file.  If it\n",
       "          does not contain an _absolute_ path, the file name is\n",
       "          _relative_ to the current working directory, 'getwd()'.\n",
       "          Tilde-expansion is performed where supported.  This can be a\n",
       "          compressed file (see 'file').\n",
       "\n",
       "          Alternatively, 'file' can be a readable text-mode connection\n",
       "          (which will be opened for reading if necessary, and if so\n",
       "          'close'd (and hence destroyed) at the end of the function\n",
       "          call).  (If 'stdin()' is used, the prompts for lines may be\n",
       "          somewhat confusing.  Terminate input with a blank line or an\n",
       "          EOF signal, 'Ctrl-D' on Unix and 'Ctrl-Z' on Windows.  Any\n",
       "          pushback on 'stdin()' will be cleared before return.)\n",
       "\n",
       "          'file' can also be a complete URL.  (For the supported URL\n",
       "          schemes, see the 'URLs' section of the help for 'url'.)\n",
       "\n",
       "  header: a logical value indicating whether the file contains the\n",
       "          names of the variables as its first line.  If missing, the\n",
       "          value is determined from the file format: 'header' is set to\n",
       "          'TRUE' if and only if the first row contains one fewer field\n",
       "          than the number of columns.\n",
       "\n",
       "     sep: the field separator character.  Values on each line of the\n",
       "          file are separated by this character.  If 'sep = \"\"' (the\n",
       "          default for 'read.table') the separator is 'white space',\n",
       "          that is one or more spaces, tabs, newlines or carriage\n",
       "          returns.\n",
       "\n",
       "   quote: the set of quoting characters. To disable quoting altogether,\n",
       "          use 'quote = \"\"'.  See 'scan' for the behaviour on quotes\n",
       "          embedded in quotes.  Quoting is only considered for columns\n",
       "          read as character, which is all of them unless 'colClasses'\n",
       "          is specified.\n",
       "\n",
       "     dec: the character used in the file for decimal points.\n",
       "\n",
       "numerals: string indicating how to convert numbers whose conversion to\n",
       "          double precision would lose accuracy, see 'type.convert'.\n",
       "          Can be abbreviated.  (Applies also to complex-number inputs.)\n",
       "\n",
       "row.names: a vector of row names.  This can be a vector giving the\n",
       "          actual row names, or a single number giving the column of the\n",
       "          table which contains the row names, or character string\n",
       "          giving the name of the table column containing the row names.\n",
       "\n",
       "          If there is a header and the first row contains one fewer\n",
       "          field than the number of columns, the first column in the\n",
       "          input is used for the row names.  Otherwise if 'row.names' is\n",
       "          missing, the rows are numbered.\n",
       "\n",
       "          Using 'row.names = NULL' forces row numbering. Missing or\n",
       "          'NULL' 'row.names' generate row names that are considered to\n",
       "          be 'automatic' (and not preserved by 'as.matrix').\n",
       "\n",
       "col.names: a vector of optional names for the variables.  The default\n",
       "          is to use '\"V\"' followed by the column number.\n",
       "\n",
       "   as.is: the default behavior of 'read.table' is to convert character\n",
       "          variables (which are not converted to logical, numeric or\n",
       "          complex) to factors.  The variable 'as.is' controls the\n",
       "          conversion of columns not otherwise specified by\n",
       "          'colClasses'.  Its value is either a vector of logicals\n",
       "          (values are recycled if necessary), or a vector of numeric or\n",
       "          character indices which specify which columns should not be\n",
       "          converted to factors.\n",
       "\n",
       "          Note: to suppress all conversions including those of numeric\n",
       "          columns, set 'colClasses = \"character\"'.\n",
       "\n",
       "          Note that 'as.is' is specified per column (not per variable)\n",
       "          and so includes the column of row names (if any) and any\n",
       "          columns to be skipped.\n",
       "\n",
       "na.strings: a character vector of strings which are to be interpreted\n",
       "          as 'NA' values.  Blank fields are also considered to be\n",
       "          missing values in logical, integer, numeric and complex\n",
       "          fields.  Note that the test happens _after_ white space is\n",
       "          stripped from the input, so 'na.strings' values may need\n",
       "          their own white space stripped in advance.\n",
       "\n",
       "colClasses: character.  A vector of classes to be assumed for the\n",
       "          columns.  If unnamed, recycled as necessary.  If named, names\n",
       "          are matched with unspecified values being taken to be 'NA'.\n",
       "\n",
       "          Possible values are 'NA' (the default, when 'type.convert' is\n",
       "          used), '\"NULL\"' (when the column is skipped), one of the\n",
       "          atomic vector classes (logical, integer, numeric, complex,\n",
       "          character, raw), or '\"factor\"', '\"Date\"' or '\"POSIXct\"'.\n",
       "          Otherwise there needs to be an 'as' method (from package\n",
       "          'methods') for conversion from '\"character\"' to the specified\n",
       "          formal class.\n",
       "\n",
       "          Note that 'colClasses' is specified per column (not per\n",
       "          variable) and so includes the column of row names (if any).\n",
       "\n",
       "   nrows: integer: the maximum number of rows to read in.  Negative and\n",
       "          other invalid values are ignored.\n",
       "\n",
       "    skip: integer: the number of lines of the data file to skip before\n",
       "          beginning to read data.\n",
       "\n",
       "check.names: logical.  If 'TRUE' then the names of the variables in the\n",
       "          data frame are checked to ensure that they are syntactically\n",
       "          valid variable names.  If necessary they are adjusted (by\n",
       "          'make.names') so that they are, and also to ensure that there\n",
       "          are no duplicates.\n",
       "\n",
       "    fill: logical. If 'TRUE' then in case the rows have unequal length,\n",
       "          blank fields are implicitly added.  See 'Details'.\n",
       "\n",
       "strip.white: logical. Used only when 'sep' has been specified, and\n",
       "          allows the stripping of leading and trailing white space from\n",
       "          unquoted 'character' fields ('numeric' fields are always\n",
       "          stripped).  See 'scan' for further details (including the\n",
       "          exact meaning of 'white space'), remembering that the columns\n",
       "          may include the row names.\n",
       "\n",
       "blank.lines.skip: logical: if 'TRUE' blank lines in the input are\n",
       "          ignored.\n",
       "\n",
       "comment.char: character: a character vector of length one containing a\n",
       "          single character or an empty string.  Use '\"\"' to turn off\n",
       "          the interpretation of comments altogether.\n",
       "\n",
       "allowEscapes: logical.  Should C-style escapes such as '\\n' be\n",
       "          processed or read verbatim (the default)?  Note that if not\n",
       "          within quotes these could be interpreted as a delimiter (but\n",
       "          not as a comment character).  For more details see 'scan'.\n",
       "\n",
       "   flush: logical: if 'TRUE', 'scan' will flush to the end of the line\n",
       "          after reading the last of the fields requested.  This allows\n",
       "          putting comments after the last field.\n",
       "\n",
       "stringsAsFactors: logical: should character vectors be converted to\n",
       "          factors?  Note that this is overridden by 'as.is' and\n",
       "          'colClasses', both of which allow finer control.\n",
       "\n",
       "fileEncoding: character string: if non-empty declares the encoding used\n",
       "          on a file (not a connection) so the character data can be\n",
       "          re-encoded.  See the 'Encoding' section of the help for\n",
       "          'file', the 'R Data Import/Export Manual' and 'Note'.\n",
       "\n",
       "encoding: encoding to be assumed for input strings.  It is used to mark\n",
       "          character strings as known to be in Latin-1 or UTF-8 (see\n",
       "          'Encoding'): it is not used to re-encode the input, but\n",
       "          allows R to handle encoded strings in their native encoding\n",
       "          (if one of those two).  See 'Value' and 'Note'.\n",
       "\n",
       "    text: character string: if 'file' is not supplied and this is, then\n",
       "          data are read from the value of 'text' via a text connection.\n",
       "          Notice that a literal string can be used to include (small)\n",
       "          data sets within R code.\n",
       "\n",
       " skipNul: logical: should nuls be skipped?\n",
       "\n",
       "     ...: Further arguments to be passed to 'read.table'.\n",
       "\n",
       "_\bD_\be_\bt_\ba_\bi_\bl_\bs:\n",
       "\n",
       "     This function is the principal means of reading tabular data into\n",
       "     R.\n",
       "\n",
       "     Unless 'colClasses' is specified, all columns are read as\n",
       "     character columns and then converted using 'type.convert' to\n",
       "     logical, integer, numeric, complex or (depending on 'as.is')\n",
       "     factor as appropriate.  Quotes are (by default) interpreted in all\n",
       "     fields, so a column of values like '\"42\"' will result in an\n",
       "     integer column.\n",
       "\n",
       "     A field or line is 'blank' if it contains nothing (except\n",
       "     whitespace if no separator is specified) before a comment\n",
       "     character or the end of the field or line.\n",
       "\n",
       "     If 'row.names' is not specified and the header line has one less\n",
       "     entry than the number of columns, the first column is taken to be\n",
       "     the row names.  This allows data frames to be read in from the\n",
       "     format in which they are printed.  If 'row.names' is specified and\n",
       "     does not refer to the first column, that column is discarded from\n",
       "     such files.\n",
       "\n",
       "     The number of data columns is determined by looking at the first\n",
       "     five lines of input (or the whole input if it has less than five\n",
       "     lines), or from the length of 'col.names' if it is specified and\n",
       "     is longer.  This could conceivably be wrong if 'fill' or\n",
       "     'blank.lines.skip' are true, so specify 'col.names' if necessary\n",
       "     (as in the 'Examples').\n",
       "\n",
       "     'read.csv' and 'read.csv2' are identical to 'read.table' except\n",
       "     for the defaults.  They are intended for reading 'comma separated\n",
       "     value' files ('.csv') or ('read.csv2') the variant used in\n",
       "     countries that use a comma as decimal point and a semicolon as\n",
       "     field separator.  Similarly, 'read.delim' and 'read.delim2' are\n",
       "     for reading delimited files, defaulting to the TAB character for\n",
       "     the delimiter.  Notice that 'header = TRUE' and 'fill = TRUE' in\n",
       "     these variants, and that the comment character is disabled.\n",
       "\n",
       "     The rest of the line after a comment character is skipped; quotes\n",
       "     are not processed in comments.  Complete comment lines are allowed\n",
       "     provided 'blank.lines.skip = TRUE'; however, comment lines prior\n",
       "     to the header must have the comment character in the first\n",
       "     non-blank column.\n",
       "\n",
       "     Quoted fields with embedded newlines are supported except after a\n",
       "     comment character.  Embedded nuls are unsupported: skipping them\n",
       "     (with 'skipNul = TRUE') may work.\n",
       "\n",
       "_\bV_\ba_\bl_\bu_\be:\n",
       "\n",
       "     A data frame ('data.frame') containing a representation of the\n",
       "     data in the file.\n",
       "\n",
       "     Empty input is an error unless 'col.names' is specified, when a\n",
       "     0-row data frame is returned: similarly giving just a header line\n",
       "     if 'header = TRUE' results in a 0-row data frame.  Note that in\n",
       "     either case the columns will be logical unless 'colClasses' was\n",
       "     supplied.\n",
       "\n",
       "     Character strings in the result (including factor levels) will\n",
       "     have a declared encoding if 'encoding' is '\"latin1\"' or '\"UTF-8\"'.\n",
       "\n",
       "_\bM_\be_\bm_\bo_\br_\by _\bu_\bs_\ba_\bg_\be:\n",
       "\n",
       "     These functions can use a surprising amount of memory when reading\n",
       "     large files.  There is extensive discussion in the 'R Data\n",
       "     Import/Export' manual, supplementing the notes here.\n",
       "\n",
       "     Less memory will be used if 'colClasses' is specified as one of\n",
       "     the six atomic vector classes.  This can be particularly so when\n",
       "     reading a column that takes many distinct numeric values, as\n",
       "     storing each distinct value as a character string can take up to\n",
       "     14 times as much memory as storing it as an integer.\n",
       "\n",
       "     Using 'nrows', even as a mild over-estimate, will help memory\n",
       "     usage.\n",
       "\n",
       "     Using 'comment.char = \"\"' will be appreciably faster than the\n",
       "     'read.table' default.\n",
       "\n",
       "     'read.table' is not the right tool for reading large matrices,\n",
       "     especially those with many columns: it is designed to read _data\n",
       "     frames_ which may have columns of very different classes.  Use\n",
       "     'scan' instead for matrices.\n",
       "\n",
       "_\bN_\bo_\bt_\be:\n",
       "\n",
       "     The columns referred to in 'as.is' and 'colClasses' include the\n",
       "     column of row names (if any).\n",
       "\n",
       "     There are two approaches for reading input that is not in the\n",
       "     local encoding.  If the input is known to be UTF-8 or Latin1, use\n",
       "     the 'encoding' argument to declare that.  If the input is in some\n",
       "     other encoding, then it may be translated on input.  The\n",
       "     'fileEncoding' argument achieves this by setting up a connection\n",
       "     to do the re-encoding into the current locale.  Note that on\n",
       "     Windows or other systems not running in a UTF-8 locale, this may\n",
       "     not be possible.\n",
       "\n",
       "_\bR_\be_\bf_\be_\br_\be_\bn_\bc_\be_\bs:\n",
       "\n",
       "     Chambers, J. M. (1992) _Data for models._ Chapter 3 of\n",
       "     _Statistical Models in S_ eds J. M. Chambers and T. J. Hastie,\n",
       "     Wadsworth & Brooks/Cole.\n",
       "\n",
       "_\bS_\be_\be _\bA_\bl_\bs_\bo:\n",
       "\n",
       "     The 'R Data Import/Export' manual.\n",
       "\n",
       "     'scan', 'type.convert', 'read.fwf' for reading _f_ixed _w_idth\n",
       "     _f_ormatted input; 'write.table'; 'data.frame'.\n",
       "\n",
       "     'count.fields' can be useful to determine problems with reading\n",
       "     files which result in reports of incorrect record lengths (see the\n",
       "     'Examples' below).\n",
       "\n",
       "     <URL: https://tools.ietf.org/html/rfc4180> for the IANA definition\n",
       "     of CSV files (which requires comma as separator and CRLF line\n",
       "     endings).\n",
       "\n",
       "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
       "\n",
       "     ## using count.fields to handle unknown maximum number of fields\n",
       "     ## when fill = TRUE\n",
       "     test1 <- c(1:5, \"6,7\", \"8,9,10\")\n",
       "     tf <- tempfile()\n",
       "     writeLines(test1, tf)\n",
       "     \n",
       "     read.csv(tf, fill = TRUE) # 1 column\n",
       "     ncol <- max(count.fields(tf, sep = \",\"))\n",
       "     read.csv(tf, fill = TRUE, header = FALSE,\n",
       "              col.names = paste0(\"V\", seq_len(ncol)))\n",
       "     unlink(tf)\n",
       "     \n",
       "     ## \"Inline\" data set, using text=\n",
       "     ## Notice that leading and trailing empty lines are auto-trimmed\n",
       "     \n",
       "     read.table(header = TRUE, text = \"\n",
       "     a b\n",
       "     1 2\n",
       "     3 4\n",
       "     \")\n",
       "     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?read.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>5</td></tr>\n",
       "\t<tr><td>1</td><td>5</td></tr>\n",
       "\t<tr><td>1</td><td>5</td></tr>\n",
       "\t<tr><td>1</td><td>5</td></tr>\n",
       "\t<tr><td>1</td><td>5</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       "\t 1 & 5\\\\\n",
       "\t 1 & 5\\\\\n",
       "\t 1 & 5\\\\\n",
       "\t 1 & 5\\\\\n",
       "\t 1 & 5\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 1 | 5 | \n",
       "| 1 | 5 | \n",
       "| 1 | 5 | \n",
       "| 1 | 5 | \n",
       "| 1 | 5 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     [,1] [,2]\n",
       "[1,] 1    5   \n",
       "[2,] 1    5   \n",
       "[3,] 1    5   \n",
       "[4,] 1    5   \n",
       "[5,] 1    5   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
